{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "#from wordcloud import WordCloud\n",
    "import re\n",
    "import os\n",
    "from sqlalchemy import create_engine # database connection\n",
    "import datetime as dt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skmultilearn.adapt import mlknn\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>title</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "      <th>synopsis_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0057603</td>\n",
       "      <td>I tre volti della paura</td>\n",
       "      <td>Note: this synopsis is for the orginal Italian...</td>\n",
       "      <td>cult, horror, gothic, murder, atmospheric</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1733125</td>\n",
       "      <td>Dungeons &amp; Dragons: The Book of Vile Darkness</td>\n",
       "      <td>Two thousand years ago, Nhagruul the Foul, a s...</td>\n",
       "      <td>violence</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0033045</td>\n",
       "      <td>The Shop Around the Corner</td>\n",
       "      <td>Matuschek's, a gift store in Budapest, is the ...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0113862</td>\n",
       "      <td>Mr. Holland's Opus</td>\n",
       "      <td>Glenn Holland, not a morning person by anyone'...</td>\n",
       "      <td>inspiring, romantic, stupid, feel-good</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0086250</td>\n",
       "      <td>Scarface</td>\n",
       "      <td>In May 1980, a Cuban man named Tony Montana (A...</td>\n",
       "      <td>cruelty, murder, dramatic, cult, violence, atm...</td>\n",
       "      <td>val</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     imdb_id                                          title  \\\n",
       "0  tt0057603                        I tre volti della paura   \n",
       "1  tt1733125  Dungeons & Dragons: The Book of Vile Darkness   \n",
       "2  tt0033045                     The Shop Around the Corner   \n",
       "3  tt0113862                             Mr. Holland's Opus   \n",
       "4  tt0086250                                       Scarface   \n",
       "\n",
       "                                       plot_synopsis  \\\n",
       "0  Note: this synopsis is for the orginal Italian...   \n",
       "1  Two thousand years ago, Nhagruul the Foul, a s...   \n",
       "2  Matuschek's, a gift store in Budapest, is the ...   \n",
       "3  Glenn Holland, not a morning person by anyone'...   \n",
       "4  In May 1980, a Cuban man named Tony Montana (A...   \n",
       "\n",
       "                                                tags  split synopsis_source  \n",
       "0          cult, horror, gothic, murder, atmospheric  train            imdb  \n",
       "1                                           violence  train            imdb  \n",
       "2                                           romantic   test            imdb  \n",
       "3             inspiring, romantic, stupid, feel-good  train            imdb  \n",
       "4  cruelty, murder, dramatic, cult, violence, atm...    val            imdb  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('mpst_full_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ankan_rokr/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for cleaning the plots of the movies\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    #text = re.sub('\\W', ' ', text)\n",
    "    #text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "# function for text cleaning \n",
    "def cleaned(text):\n",
    "    # remove backslash-apostrophe \n",
    "    text = re.sub(\"\\'\", \"\", text) \n",
    "    # remove everything except alphabets \n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "    # remove whitespaces \n",
    "    text = ' '.join(text.split()) \n",
    "    # convert text to lowercase \n",
    "    text = text.lower() \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned'] = list(data['plot_synopsis'].apply(clean_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned'] = list(data['cleaned'].apply(cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    return ' '.join(no_stopword_text)\n",
    "\n",
    "data['cleaned'] = data['cleaned'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>title</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "      <th>synopsis_source</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0057603</td>\n",
       "      <td>I tre volti della paura</td>\n",
       "      <td>Note: this synopsis is for the orginal Italian...</td>\n",
       "      <td>cult, horror, gothic, murder, atmospheric</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>note synopsis orginal italian release segments...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1733125</td>\n",
       "      <td>Dungeons &amp; Dragons: The Book of Vile Darkness</td>\n",
       "      <td>Two thousand years ago, Nhagruul the Foul, a s...</td>\n",
       "      <td>violence</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>two thousand years ago nhagruul foul sorcerer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0033045</td>\n",
       "      <td>The Shop Around the Corner</td>\n",
       "      <td>Matuschek's, a gift store in Budapest, is the ...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "      <td>matuschek gift store budapest workplace alfred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0113862</td>\n",
       "      <td>Mr. Holland's Opus</td>\n",
       "      <td>Glenn Holland, not a morning person by anyone'...</td>\n",
       "      <td>inspiring, romantic, stupid, feel-good</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>glenn holland morning person anyone standards ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0086250</td>\n",
       "      <td>Scarface</td>\n",
       "      <td>In May 1980, a Cuban man named Tony Montana (A...</td>\n",
       "      <td>cruelty, murder, dramatic, cult, violence, atm...</td>\n",
       "      <td>val</td>\n",
       "      <td>imdb</td>\n",
       "      <td>may cuban man named tony montana al pacino cla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     imdb_id                                          title  \\\n",
       "0  tt0057603                        I tre volti della paura   \n",
       "1  tt1733125  Dungeons & Dragons: The Book of Vile Darkness   \n",
       "2  tt0033045                     The Shop Around the Corner   \n",
       "3  tt0113862                             Mr. Holland's Opus   \n",
       "4  tt0086250                                       Scarface   \n",
       "\n",
       "                                       plot_synopsis  \\\n",
       "0  Note: this synopsis is for the orginal Italian...   \n",
       "1  Two thousand years ago, Nhagruul the Foul, a s...   \n",
       "2  Matuschek's, a gift store in Budapest, is the ...   \n",
       "3  Glenn Holland, not a morning person by anyone'...   \n",
       "4  In May 1980, a Cuban man named Tony Montana (A...   \n",
       "\n",
       "                                                tags  split synopsis_source  \\\n",
       "0          cult, horror, gothic, murder, atmospheric  train            imdb   \n",
       "1                                           violence  train            imdb   \n",
       "2                                           romantic   test            imdb   \n",
       "3             inspiring, romantic, stupid, feel-good  train            imdb   \n",
       "4  cruelty, murder, dramatic, cult, violence, atm...    val            imdb   \n",
       "\n",
       "                                             cleaned  \n",
       "0  note synopsis orginal italian release segments...  \n",
       "1  two thousand years ago nhagruul foul sorcerer ...  \n",
       "2  matuschek gift store budapest workplace alfred...  \n",
       "3  glenn holland morning person anyone standards ...  \n",
       "4  may cuban man named tony montana al pacino cla...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =  data['split']=='train'\n",
    "train = data[train_data]\n",
    "\n",
    "   \n",
    "    \n",
    "test_data =  data['split']=='test'\n",
    "test = data[test_data]\n",
    "\n",
    "  \n",
    "    \n",
    "validation_data =  data['split']=='val'\n",
    "val = data[validation_data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tags = CountVectorizer(tokenizer = lambda x: x.split(','), binary='true')\n",
    "y_train = vectorizer_tags.fit_transform(train['tags'])\n",
    "y_test = vectorizer_tags.transform(test['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9489, 142)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:00:03.718197\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = datetime.now()\n",
    "vectorizer_unigram = TfidfVectorizer(min_df=5, max_features=20000, smooth_idf=True, norm=\"l2\", \\\n",
    "                             tokenizer = lambda x: x.split(), sublinear_tf=False, ngram_range=(1,1))\n",
    "x_train_multilabel_unigram = vectorizer_unigram.fit_transform(train['cleaned'])\n",
    "x_test_multilabel_unigram = vectorizer_unigram.transform(test['cleaned'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.0030343897505057315\n",
      "Hamming loss  0.055070137615985865\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1611, Recall: 0.3732, F1-measure: 0.2250\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0726, Recall: 0.1633, F1-measure: 0.0967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.09      0.07        35\n",
      "           1       0.14      0.43      0.22       117\n",
      "           2       0.05      0.08      0.06        26\n",
      "           3       0.06      0.18      0.09        11\n",
      "           4       0.11      0.31      0.16        13\n",
      "           5       0.03      0.08      0.04        26\n",
      "           6       0.04      0.07      0.05        15\n",
      "           7       0.05      0.19      0.08        75\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.03      0.03      0.03        31\n",
      "          10       0.05      0.12      0.07         8\n",
      "          11       0.02      0.05      0.03        20\n",
      "          12       0.06      0.18      0.09        79\n",
      "          13       0.08      0.22      0.12         9\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.05      0.07      0.06        15\n",
      "          16       0.00      0.00      0.00        11\n",
      "          17       0.08      0.23      0.12       120\n",
      "          18       0.04      0.08      0.05        24\n",
      "          19       0.05      0.11      0.07        72\n",
      "          20       0.22      0.47      0.30       351\n",
      "          21       0.02      0.03      0.03        32\n",
      "          22       0.05      0.11      0.07        35\n",
      "          23       0.02      0.03      0.02        29\n",
      "          24       0.02      0.04      0.03        49\n",
      "          25       0.14      0.35      0.20       142\n",
      "          26       0.15      0.25      0.18        65\n",
      "          27       0.05      0.10      0.07        10\n",
      "          28       0.24      0.44      0.31       515\n",
      "          29       0.17      0.42      0.24        90\n",
      "          30       0.16      0.54      0.25        65\n",
      "          31       0.07      0.11      0.08         9\n",
      "          32       0.12      0.38      0.18        21\n",
      "          33       0.11      0.24      0.15        54\n",
      "          34       0.10      0.26      0.14        19\n",
      "          35       0.02      0.04      0.03        26\n",
      "          36       0.18      0.60      0.28        78\n",
      "          37       0.11      0.29      0.16       150\n",
      "          38       0.10      0.23      0.14        82\n",
      "          39       0.03      0.05      0.04        19\n",
      "          40       0.04      0.07      0.05        28\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.03      0.07      0.04        60\n",
      "          43       0.49      0.64      0.55       885\n",
      "          44       0.06      0.18      0.09        66\n",
      "          45       0.16      0.55      0.25       111\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.08      0.21      0.12        38\n",
      "          48       0.06      0.13      0.08        31\n",
      "          49       0.02      0.06      0.03        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.09      0.21      0.13        42\n",
      "          52       0.15      0.39      0.22       229\n",
      "          53       0.06      0.13      0.08        47\n",
      "          54       0.00      0.00      0.00         8\n",
      "          55       0.01      0.04      0.02        24\n",
      "          56       0.19      0.49      0.27       268\n",
      "          57       0.18      0.36      0.24       311\n",
      "          58       0.13      0.29      0.18       142\n",
      "          59       0.14      0.30      0.19       138\n",
      "          60       0.15      0.45      0.22        53\n",
      "          61       0.07      0.18      0.11        49\n",
      "          62       0.03      0.08      0.05        61\n",
      "          63       0.03      0.05      0.04        37\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.14      0.42      0.21       153\n",
      "          66       0.06      0.10      0.08        20\n",
      "          67       0.02      0.04      0.03        52\n",
      "          68       0.37      0.65      0.47       593\n",
      "          69       0.00      0.00      0.00         4\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.05      0.05      0.05        21\n",
      "          72       0.06      0.08      0.07        12\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00        11\n",
      "          75       0.29      0.40      0.33         5\n",
      "          76       0.12      0.11      0.12         9\n",
      "          77       0.09      0.20      0.12        15\n",
      "          78       0.00      0.00      0.00         4\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.00      0.00      0.00        14\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.04      0.05      0.05        20\n",
      "          83       0.00      0.00      0.00        36\n",
      "          84       0.00      0.00      0.00         9\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.14      0.36      0.20       248\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.00      0.00      0.00        25\n",
      "          91       0.11      0.27      0.15       200\n",
      "          92       0.03      0.11      0.05         9\n",
      "          93       0.04      0.12      0.06        50\n",
      "          94       0.00      0.00      0.00        13\n",
      "          95       0.05      0.09      0.06        34\n",
      "          96       0.00      0.00      0.00        17\n",
      "          97       0.27      0.46      0.34        48\n",
      "          98       0.00      1.00      0.00         1\n",
      "          99       0.03      0.07      0.05        81\n",
      "         100       0.17      0.48      0.25       100\n",
      "         101       0.10      0.28      0.14        18\n",
      "         102       0.14      0.33      0.20         3\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.11      0.10      0.11        10\n",
      "         105       0.11      0.33      0.17         6\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.13      0.29      0.18        14\n",
      "         108       0.06      0.05      0.05        22\n",
      "         109       0.07      0.19      0.10        54\n",
      "         110       0.11      0.08      0.09        13\n",
      "         111       0.07      0.08      0.08        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.03      0.06      0.04        33\n",
      "         114       0.18      0.43      0.25       270\n",
      "         115       0.05      0.10      0.07        51\n",
      "         116       0.04      0.12      0.06        34\n",
      "         117       0.00      0.00      0.00         4\n",
      "         118       0.18      0.36      0.24        91\n",
      "         119       0.00      0.00      0.00         5\n",
      "         120       0.00      0.00      0.00        11\n",
      "         121       0.08      0.14      0.10        28\n",
      "         122       0.00      0.00      0.00         9\n",
      "         123       0.43      0.44      0.43       166\n",
      "         124       0.00      0.00      0.00        18\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.00      0.00      0.00        13\n",
      "         127       0.17      0.41      0.24       239\n",
      "         128       0.27      0.66      0.39       276\n",
      "         129       0.00      0.00      0.00         6\n",
      "         130       0.06      0.06      0.06        35\n",
      "         131       0.07      0.15      0.10        13\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         5\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.07      0.24      0.11        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.09      0.16      0.12        67\n",
      "         139       0.19      0.49      0.28       318\n",
      "         140       0.12      0.20      0.15        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.16      0.37      0.23      9022\n",
      "   macro avg       0.07      0.16      0.10      9022\n",
      "weighted avg       0.19      0.37      0.25      9022\n",
      " samples avg       0.16      0.38      0.20      9022\n",
      "\n",
      "Time taken to run this cell : 0:00:11.706215\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs=-1)\n",
    "classifier.fit(x_train_multilabel_unigram,y_train)\n",
    "predictions = classifier.predict (x_test_multilabel_unigram)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:00:26.864846\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = datetime.now()\n",
    "vectorizer_bigram = TfidfVectorizer(min_df=5, max_features=20000, smooth_idf=True, norm=\"l2\", \\\n",
    "                             tokenizer = lambda x: x.split(), sublinear_tf=False, ngram_range=(2,2))\n",
    "x_train_multilabel_bigram = vectorizer_bigram.fit_transform(train['cleaned'])\n",
    "x_test_multilabel_bigram = vectorizer_bigram.transform(test['cleaned'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.02191503708698584\n",
      "Hamming loss  0.03362284292403104\n",
      "Micro-average quality numbers\n",
      "Precision: 0.2403, Recall: 0.2635, F1-measure: 0.2513\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0809, Recall: 0.0778, F1-measure: 0.0742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        35\n",
      "           1       0.24      0.33      0.28       117\n",
      "           2       0.00      0.00      0.00        26\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.13      0.15      0.14        13\n",
      "           5       0.25      0.15      0.19        26\n",
      "           6       0.00      0.00      0.00        15\n",
      "           7       0.09      0.11      0.10        75\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.09      0.03      0.05        31\n",
      "          10       0.40      0.25      0.31         8\n",
      "          11       0.00      0.00      0.00        20\n",
      "          12       0.07      0.06      0.07        79\n",
      "          13       0.00      0.00      0.00         9\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.00      0.00      0.00        15\n",
      "          16       0.00      0.00      0.00        11\n",
      "          17       0.12      0.16      0.14       120\n",
      "          18       0.00      0.00      0.00        24\n",
      "          19       0.08      0.03      0.04        72\n",
      "          20       0.23      0.38      0.29       351\n",
      "          21       0.00      0.00      0.00        32\n",
      "          22       0.14      0.03      0.05        35\n",
      "          23       0.00      0.00      0.00        29\n",
      "          24       0.07      0.02      0.03        49\n",
      "          25       0.16      0.20      0.18       142\n",
      "          26       0.25      0.12      0.16        65\n",
      "          27       0.00      0.00      0.00        10\n",
      "          28       0.27      0.38      0.32       515\n",
      "          29       0.23      0.21      0.22        90\n",
      "          30       0.17      0.23      0.20        65\n",
      "          31       0.00      0.00      0.00         9\n",
      "          32       0.43      0.14      0.21        21\n",
      "          33       0.06      0.04      0.05        54\n",
      "          34       0.07      0.05      0.06        19\n",
      "          35       0.00      0.00      0.00        26\n",
      "          36       0.19      0.32      0.24        78\n",
      "          37       0.17      0.19      0.18       150\n",
      "          38       0.15      0.11      0.13        82\n",
      "          39       0.00      0.00      0.00        19\n",
      "          40       0.00      0.00      0.00        28\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.03      0.02      0.02        60\n",
      "          43       0.48      0.57      0.52       885\n",
      "          44       0.12      0.11      0.11        66\n",
      "          45       0.24      0.41      0.30       111\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.05      0.03      0.03        38\n",
      "          48       0.00      0.00      0.00        31\n",
      "          49       0.12      0.06      0.08        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.10      0.05      0.06        42\n",
      "          52       0.18      0.23      0.20       229\n",
      "          53       0.00      0.00      0.00        47\n",
      "          54       0.00      0.00      0.00         8\n",
      "          55       0.00      0.00      0.00        24\n",
      "          56       0.22      0.37      0.28       268\n",
      "          57       0.20      0.31      0.24       311\n",
      "          58       0.18      0.20      0.19       142\n",
      "          59       0.16      0.14      0.15       138\n",
      "          60       0.11      0.09      0.10        53\n",
      "          61       0.14      0.06      0.08        49\n",
      "          62       0.12      0.03      0.05        61\n",
      "          63       0.00      0.00      0.00        37\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.16      0.24      0.19       153\n",
      "          66       0.00      0.00      0.00        20\n",
      "          67       0.04      0.02      0.03        52\n",
      "          68       0.39      0.55      0.46       593\n",
      "          69       0.00      0.00      0.00         4\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.00      0.00      0.00        21\n",
      "          72       0.00      0.00      0.00        12\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00        11\n",
      "          75       0.17      0.20      0.18         5\n",
      "          76       0.25      0.11      0.15         9\n",
      "          77       0.25      0.07      0.11        15\n",
      "          78       0.00      0.00      0.00         4\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.00      0.00      0.00        14\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.00      0.00      0.00        20\n",
      "          83       0.00      0.00      0.00        36\n",
      "          84       0.00      0.00      0.00         9\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.16      0.26      0.20       248\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.11      0.04      0.06        25\n",
      "          91       0.11      0.14      0.12       200\n",
      "          92       0.00      0.00      0.00         9\n",
      "          93       0.05      0.04      0.05        50\n",
      "          94       0.00      0.00      0.00        13\n",
      "          95       0.00      0.00      0.00        34\n",
      "          96       0.00      0.00      0.00        17\n",
      "          97       0.28      0.19      0.23        48\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.07      0.02      0.04        81\n",
      "         100       0.20      0.20      0.20       100\n",
      "         101       0.13      0.17      0.15        18\n",
      "         102       0.00      0.00      0.00         3\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.00      0.00      0.00        10\n",
      "         105       0.50      0.33      0.40         6\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.14      0.07      0.10        14\n",
      "         108       0.00      0.00      0.00        22\n",
      "         109       0.09      0.06      0.07        54\n",
      "         110       0.00      0.00      0.00        13\n",
      "         111       0.00      0.00      0.00        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00        33\n",
      "         114       0.18      0.24      0.20       270\n",
      "         115       0.00      0.00      0.00        51\n",
      "         116       0.04      0.03      0.03        34\n",
      "         117       0.00      0.00      0.00         4\n",
      "         118       0.25      0.10      0.14        91\n",
      "         119       0.00      0.00      0.00         5\n",
      "         120       0.00      0.00      0.00        11\n",
      "         121       0.00      0.00      0.00        28\n",
      "         122       0.00      0.00      0.00         9\n",
      "         123       0.47      0.30      0.37       166\n",
      "         124       0.00      0.00      0.00        18\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.00      0.00      0.00        13\n",
      "         127       0.16      0.19      0.17       239\n",
      "         128       0.29      0.56      0.38       276\n",
      "         129       0.00      0.00      0.00         6\n",
      "         130       0.00      0.00      0.00        35\n",
      "         131       0.00      0.00      0.00        13\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         5\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.08      0.08      0.08        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.19      0.09      0.12        67\n",
      "         139       0.20      0.35      0.26       318\n",
      "         140       0.00      0.00      0.00        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.24      0.26      0.25      9022\n",
      "   macro avg       0.08      0.08      0.07      9022\n",
      "weighted avg       0.21      0.26      0.23      9022\n",
      " samples avg       0.21      0.25      0.20      9022\n",
      "\n",
      "Time taken to run this cell : 0:00:04.411019\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs=-1)\n",
    "classifier.fit(x_train_multilabel_bigram,y_train)\n",
    "predictions = classifier.predict (x_test_multilabel_bigram)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:00:35.543909\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "vectorizer_trigram = TfidfVectorizer(min_df=10, max_features=20000, smooth_idf=True, norm=\"l2\", \\\n",
    "                             tokenizer = lambda x: x.split(), sublinear_tf=False, ngram_range=(3,3))\n",
    "x_train_multilabel_trigram = vectorizer_trigram.fit_transform(train['cleaned'])\n",
    "x_test_multilabel_trigram = vectorizer_trigram.transform(test['cleaned'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.00033715441672285906\n",
      "Hamming loss  0.11498865071752158\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0565, Recall: 0.2781, F1-measure: 0.0939\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0289, Recall: 0.1425, F1-measure: 0.0442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.14      0.03        35\n",
      "           1       0.08      0.36      0.13       117\n",
      "           2       0.01      0.08      0.02        26\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.01      0.08      0.01        13\n",
      "           5       0.02      0.19      0.03        26\n",
      "           6       0.01      0.07      0.01        15\n",
      "           7       0.03      0.20      0.05        75\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.01      0.13      0.02        31\n",
      "          10       0.01      0.25      0.02         8\n",
      "          11       0.01      0.15      0.02        20\n",
      "          12       0.03      0.20      0.06        79\n",
      "          13       0.01      0.11      0.01         9\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.00      0.07      0.01        15\n",
      "          16       0.01      0.27      0.02        11\n",
      "          17       0.05      0.23      0.08       120\n",
      "          18       0.01      0.08      0.02        24\n",
      "          19       0.03      0.19      0.05        72\n",
      "          20       0.14      0.33      0.20       351\n",
      "          21       0.02      0.22      0.04        32\n",
      "          22       0.01      0.09      0.01        35\n",
      "          23       0.00      0.00      0.00        29\n",
      "          24       0.02      0.16      0.03        49\n",
      "          25       0.08      0.35      0.13       142\n",
      "          26       0.03      0.15      0.05        65\n",
      "          27       0.00      0.00      0.00        10\n",
      "          28       0.22      0.39      0.28       515\n",
      "          29       0.07      0.39      0.12        90\n",
      "          30       0.04      0.26      0.07        65\n",
      "          31       0.01      0.11      0.02         9\n",
      "          32       0.01      0.14      0.02        21\n",
      "          33       0.03      0.20      0.06        54\n",
      "          34       0.00      0.05      0.01        19\n",
      "          35       0.01      0.12      0.02        26\n",
      "          36       0.05      0.37      0.09        78\n",
      "          37       0.07      0.31      0.12       150\n",
      "          38       0.04      0.23      0.06        82\n",
      "          39       0.01      0.11      0.02        19\n",
      "          40       0.01      0.07      0.01        28\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.03      0.23      0.06        60\n",
      "          43       0.37      0.40      0.38       885\n",
      "          44       0.03      0.18      0.05        66\n",
      "          45       0.07      0.35      0.12       111\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.02      0.21      0.04        38\n",
      "          48       0.01      0.10      0.01        31\n",
      "          49       0.03      0.21      0.05        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.01      0.12      0.02        42\n",
      "          52       0.09      0.31      0.14       229\n",
      "          53       0.02      0.15      0.04        47\n",
      "          54       0.00      0.00      0.00         8\n",
      "          55       0.01      0.08      0.01        24\n",
      "          56       0.13      0.34      0.19       268\n",
      "          57       0.14      0.36      0.20       311\n",
      "          58       0.06      0.25      0.10       142\n",
      "          59       0.06      0.27      0.10       138\n",
      "          60       0.02      0.19      0.04        53\n",
      "          61       0.03      0.29      0.06        49\n",
      "          62       0.02      0.18      0.04        61\n",
      "          63       0.02      0.14      0.03        37\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.07      0.27      0.11       153\n",
      "          66       0.01      0.15      0.02        20\n",
      "          67       0.03      0.25      0.05        52\n",
      "          68       0.26      0.38      0.31       593\n",
      "          69       0.02      0.25      0.04         4\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.00      0.05      0.01        21\n",
      "          72       0.01      0.17      0.03        12\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00        11\n",
      "          75       0.00      0.00      0.00         5\n",
      "          76       0.01      0.11      0.01         9\n",
      "          77       0.02      0.33      0.04        15\n",
      "          78       0.00      0.00      0.00         4\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.00      0.00      0.00        14\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.01      0.10      0.01        20\n",
      "          83       0.03      0.28      0.05        36\n",
      "          84       0.01      0.11      0.01         9\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.09      0.29      0.14       248\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.02      0.20      0.03        25\n",
      "          91       0.07      0.19      0.10       200\n",
      "          92       0.00      0.00      0.00         9\n",
      "          93       0.02      0.16      0.04        50\n",
      "          94       0.01      0.08      0.01        13\n",
      "          95       0.02      0.21      0.03        34\n",
      "          96       0.01      0.12      0.02        17\n",
      "          97       0.04      0.29      0.07        48\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.03      0.19      0.05        81\n",
      "         100       0.07      0.34      0.11       100\n",
      "         101       0.02      0.22      0.03        18\n",
      "         102       0.01      0.33      0.03         3\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.01      0.10      0.01        10\n",
      "         105       0.02      0.17      0.03         6\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.02      0.29      0.04        14\n",
      "         108       0.01      0.14      0.02        22\n",
      "         109       0.01      0.11      0.02        54\n",
      "         110       0.01      0.08      0.02        13\n",
      "         111       0.00      0.00      0.00        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.02      0.15      0.03        33\n",
      "         114       0.12      0.29      0.17       270\n",
      "         115       0.02      0.16      0.04        51\n",
      "         116       0.01      0.15      0.02        34\n",
      "         117       0.00      0.00      0.00         4\n",
      "         118       0.06      0.30      0.09        91\n",
      "         119       0.01      0.20      0.01         5\n",
      "         120       0.00      0.00      0.00        11\n",
      "         121       0.01      0.11      0.02        28\n",
      "         122       0.00      0.00      0.00         9\n",
      "         123       0.07      0.20      0.11       166\n",
      "         124       0.00      0.00      0.00        18\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.00      0.00      0.00        13\n",
      "         127       0.08      0.21      0.11       239\n",
      "         128       0.16      0.40      0.23       276\n",
      "         129       0.00      0.00      0.00         6\n",
      "         130       0.01      0.11      0.02        35\n",
      "         131       0.01      0.08      0.02        13\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         5\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.03      0.23      0.06        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.02      0.13      0.04        67\n",
      "         139       0.12      0.26      0.17       318\n",
      "         140       0.01      0.10      0.01        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.06      0.28      0.09      9022\n",
      "   macro avg       0.03      0.14      0.04      9022\n",
      "weighted avg       0.12      0.28      0.15      9022\n",
      " samples avg       0.04      0.26      0.06      9022\n",
      "\n",
      "Time taken to run this cell : 0:00:00.737282\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs=-1)\n",
    "classifier.fit(x_train_multilabel_trigram,y_train)\n",
    "predictions = classifier.predict (x_test_multilabel_trigram)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:00:39.402924\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "vectorizer_fourgram = TfidfVectorizer(min_df=10, max_features=20000, smooth_idf=True, norm=\"l2\", \\\n",
    "                             tokenizer = lambda x: x.split(), sublinear_tf=False, ngram_range=(4,4))\n",
    "x_train_multilabel_fourgram = vectorizer_fourgram.fit_transform(train['cleaned'])\n",
    "x_test_multilabel_fourgram = vectorizer_fourgram.transform(test['cleaned'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.0\n",
      "Hamming loss  0.3896080461189253\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0185, Recall: 0.3303, F1-measure: 0.0350\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0307, Recall: 0.3675, F1-measure: 0.0210\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.94      0.02        35\n",
      "           1       0.05      0.01      0.01       117\n",
      "           2       0.00      0.00      0.00        26\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.00      1.00      0.01        13\n",
      "           5       0.00      0.00      0.00        26\n",
      "           6       0.00      0.00      0.00        15\n",
      "           7       0.02      0.01      0.02        75\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.01      1.00      0.02        31\n",
      "          10       0.00      0.00      0.00         8\n",
      "          11       0.01      0.95      0.01        20\n",
      "          12       0.03      0.96      0.05        79\n",
      "          13       0.00      0.89      0.01         9\n",
      "          14       0.00      1.00      0.00         3\n",
      "          15       0.00      0.00      0.00        15\n",
      "          16       0.00      1.00      0.01        11\n",
      "          17       0.04      0.98      0.08       120\n",
      "          18       0.00      0.00      0.00        24\n",
      "          19       0.00      0.00      0.00        72\n",
      "          20       0.28      0.03      0.06       351\n",
      "          21       0.25      0.03      0.06        32\n",
      "          22       0.00      0.00      0.00        35\n",
      "          23       0.00      0.00      0.00        29\n",
      "          24       0.02      1.00      0.03        49\n",
      "          25       0.05      0.98      0.09       142\n",
      "          26       0.12      0.02      0.03        65\n",
      "          27       0.00      0.00      0.00        10\n",
      "          28       0.17      0.98      0.29       515\n",
      "          29       0.10      0.04      0.06        90\n",
      "          30       0.18      0.09      0.12        65\n",
      "          31       0.00      1.00      0.01         9\n",
      "          32       0.00      0.00      0.00        21\n",
      "          33       0.00      0.00      0.00        54\n",
      "          34       0.01      1.00      0.01        19\n",
      "          35       0.01      1.00      0.02        26\n",
      "          36       0.03      0.01      0.02        78\n",
      "          37       0.04      0.01      0.01       150\n",
      "          38       0.00      0.00      0.00        82\n",
      "          39       0.01      1.00      0.01        19\n",
      "          40       0.00      0.00      0.00        28\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.00      0.00      0.00        60\n",
      "          43       0.52      0.03      0.05       885\n",
      "          44       0.00      0.00      0.00        66\n",
      "          45       0.11      0.02      0.03       111\n",
      "          46       0.00      1.00      0.00         1\n",
      "          47       0.10      0.08      0.09        38\n",
      "          48       0.00      0.00      0.00        31\n",
      "          49       0.00      0.00      0.00        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00        42\n",
      "          52       0.09      0.02      0.03       229\n",
      "          53       0.00      0.00      0.00        47\n",
      "          54       0.00      0.00      0.00         8\n",
      "          55       0.00      0.00      0.00        24\n",
      "          56       0.10      0.02      0.03       268\n",
      "          57       0.10      0.98      0.19       311\n",
      "          58       0.04      0.01      0.02       142\n",
      "          59       0.05      0.97      0.09       138\n",
      "          60       0.02      0.96      0.03        53\n",
      "          61       0.07      0.02      0.03        49\n",
      "          62       0.00      0.00      0.00        61\n",
      "          63       0.00      0.00      0.00        37\n",
      "          64       0.00      1.00      0.00         6\n",
      "          65       0.00      0.00      0.00       153\n",
      "          66       0.00      0.00      0.00        20\n",
      "          67       0.00      0.00      0.00        52\n",
      "          68       0.19      0.01      0.03       593\n",
      "          69       0.00      1.00      0.00         4\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.01      0.95      0.01        21\n",
      "          72       0.00      0.00      0.00        12\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      1.00      0.01        11\n",
      "          75       0.00      0.00      0.00         5\n",
      "          76       0.00      0.00      0.00         9\n",
      "          77       0.00      0.00      0.00        15\n",
      "          78       0.00      1.00      0.00         4\n",
      "          79       0.00      1.00      0.00         4\n",
      "          80       0.00      0.00      0.00        14\n",
      "          81       0.00      1.00      0.00         3\n",
      "          82       0.00      0.00      0.00        20\n",
      "          83       0.00      0.00      0.00        36\n",
      "          84       0.00      1.00      0.01         9\n",
      "          85       0.00      1.00      0.00         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      1.00      0.00         2\n",
      "          88       0.08      0.00      0.01       248\n",
      "          89       0.00      1.00      0.00         3\n",
      "          90       0.00      0.00      0.00        25\n",
      "          91       0.15      0.04      0.06       200\n",
      "          92       0.00      0.00      0.00         9\n",
      "          93       0.00      0.00      0.00        50\n",
      "          94       0.00      0.00      0.00        13\n",
      "          95       0.00      0.00      0.00        34\n",
      "          96       0.00      0.00      0.00        17\n",
      "          97       0.40      0.04      0.08        48\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00        81\n",
      "         100       0.03      0.01      0.01       100\n",
      "         101       0.09      0.17      0.12        18\n",
      "         102       0.00      1.00      0.00         3\n",
      "         103       0.00      1.00      0.00         5\n",
      "         104       0.00      1.00      0.01        10\n",
      "         105       0.00      0.00      0.00         6\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.03      0.07      0.05        14\n",
      "         108       0.01      1.00      0.02        22\n",
      "         109       0.02      0.96      0.04        54\n",
      "         110       0.00      0.92      0.01        13\n",
      "         111       0.00      1.00      0.01        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00        33\n",
      "         114       0.09      0.98      0.17       270\n",
      "         115       0.00      0.00      0.00        51\n",
      "         116       0.00      0.00      0.00        34\n",
      "         117       0.00      0.00      0.00         4\n",
      "         118       0.06      0.02      0.03        91\n",
      "         119       0.00      0.00      0.00         5\n",
      "         120       0.00      0.00      0.00        11\n",
      "         121       0.06      0.07      0.07        28\n",
      "         122       0.00      0.00      0.00         9\n",
      "         123       0.06      0.98      0.11       166\n",
      "         124       0.01      1.00      0.01        18\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.00      0.92      0.01        13\n",
      "         127       0.08      0.99      0.15       239\n",
      "         128       0.16      0.01      0.03       276\n",
      "         129       0.00      0.00      0.00         6\n",
      "         130       0.00      0.00      0.00        35\n",
      "         131       0.00      1.00      0.01        13\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      1.00      0.00         5\n",
      "         134       0.00      1.00      0.00         2\n",
      "         135       0.00      1.00      0.00         2\n",
      "         136       0.00      0.00      0.00        75\n",
      "         137       0.00      1.00      0.00         7\n",
      "         138       0.02      0.97      0.04        67\n",
      "         139       0.11      0.99      0.19       318\n",
      "         140       0.00      1.00      0.01        10\n",
      "         141       0.00      1.00      0.00         7\n",
      "\n",
      "   micro avg       0.02      0.33      0.04      9022\n",
      "   macro avg       0.03      0.37      0.02      9022\n",
      "weighted avg       0.13      0.33      0.07      9022\n",
      " samples avg       0.02      0.41      0.04      9022\n",
      "\n",
      "Time taken to run this cell : 0:00:00.810394\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs=-1)\n",
    "classifier.fit(x_train_multilabel_fourgram,y_train)\n",
    "predictions = classifier.predict (x_test_multilabel_fourgram)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:02:15.210225\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "vectorizer_ngram = TfidfVectorizer(min_df=10, max_features=20000, smooth_idf=True, norm=\"l2\", \\\n",
    "                             tokenizer = lambda x: x.split(), sublinear_tf=False, ngram_range=(1,4))\n",
    "x_train_multilabel_ngram = vectorizer_ngram.fit_transform(train['cleaned'])\n",
    "x_test_multilabel_ngram = vectorizer_ngram.transform(test['cleaned'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.0070802427511800405\n",
      "Hamming loss  0.05429135839989363\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1686, Recall: 0.3904, F1-measure: 0.2355\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0725, Recall: 0.1672, F1-measure: 0.0988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.09      0.07        35\n",
      "           1       0.14      0.48      0.22       117\n",
      "           2       0.04      0.08      0.06        26\n",
      "           3       0.07      0.18      0.10        11\n",
      "           4       0.14      0.38      0.20        13\n",
      "           5       0.03      0.08      0.04        26\n",
      "           6       0.08      0.13      0.10        15\n",
      "           7       0.06      0.24      0.10        75\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.03      0.03      0.03        31\n",
      "          10       0.04      0.12      0.06         8\n",
      "          11       0.04      0.10      0.06        20\n",
      "          12       0.06      0.19      0.09        79\n",
      "          13       0.08      0.22      0.11         9\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.05      0.07      0.06        15\n",
      "          16       0.00      0.00      0.00        11\n",
      "          17       0.07      0.23      0.11       120\n",
      "          18       0.03      0.08      0.05        24\n",
      "          19       0.07      0.18      0.10        72\n",
      "          20       0.22      0.50      0.31       351\n",
      "          21       0.04      0.06      0.05        32\n",
      "          22       0.03      0.09      0.05        35\n",
      "          23       0.02      0.03      0.02        29\n",
      "          24       0.03      0.06      0.04        49\n",
      "          25       0.13      0.33      0.19       142\n",
      "          26       0.17      0.34      0.22        65\n",
      "          27       0.04      0.10      0.06        10\n",
      "          28       0.25      0.46      0.33       515\n",
      "          29       0.15      0.48      0.23        90\n",
      "          30       0.16      0.51      0.24        65\n",
      "          31       0.05      0.11      0.07         9\n",
      "          32       0.10      0.33      0.16        21\n",
      "          33       0.09      0.24      0.14        54\n",
      "          34       0.09      0.26      0.14        19\n",
      "          35       0.03      0.08      0.05        26\n",
      "          36       0.18      0.64      0.28        78\n",
      "          37       0.12      0.33      0.18       150\n",
      "          38       0.11      0.26      0.15        82\n",
      "          39       0.03      0.05      0.04        19\n",
      "          40       0.07      0.14      0.09        28\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.03      0.10      0.05        60\n",
      "          43       0.49      0.66      0.56       885\n",
      "          44       0.07      0.21      0.10        66\n",
      "          45       0.16      0.57      0.25       111\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.09      0.24      0.13        38\n",
      "          48       0.05      0.13      0.08        31\n",
      "          49       0.01      0.03      0.02        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.08      0.21      0.12        42\n",
      "          52       0.15      0.40      0.22       229\n",
      "          53       0.06      0.13      0.08        47\n",
      "          54       0.00      0.00      0.00         8\n",
      "          55       0.01      0.04      0.02        24\n",
      "          56       0.19      0.48      0.27       268\n",
      "          57       0.18      0.38      0.24       311\n",
      "          58       0.13      0.37      0.20       142\n",
      "          59       0.13      0.30      0.19       138\n",
      "          60       0.13      0.45      0.20        53\n",
      "          61       0.08      0.20      0.11        49\n",
      "          62       0.05      0.15      0.08        61\n",
      "          63       0.04      0.08      0.05        37\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.14      0.42      0.21       153\n",
      "          66       0.05      0.10      0.06        20\n",
      "          67       0.04      0.08      0.05        52\n",
      "          68       0.38      0.66      0.48       593\n",
      "          69       0.00      0.00      0.00         4\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.05      0.05      0.05        21\n",
      "          72       0.04      0.08      0.05        12\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00        11\n",
      "          75       0.29      0.40      0.33         5\n",
      "          76       0.10      0.11      0.11         9\n",
      "          77       0.11      0.27      0.15        15\n",
      "          78       0.00      0.00      0.00         4\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.00      0.00      0.00        14\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.03      0.05      0.04        20\n",
      "          83       0.00      0.00      0.00        36\n",
      "          84       0.00      0.00      0.00         9\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.14      0.39      0.21       248\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.00      0.00      0.00        25\n",
      "          91       0.10      0.28      0.15       200\n",
      "          92       0.00      0.00      0.00         9\n",
      "          93       0.04      0.12      0.06        50\n",
      "          94       0.00      0.00      0.00        13\n",
      "          95       0.06      0.12      0.08        34\n",
      "          96       0.02      0.06      0.03        17\n",
      "          97       0.25      0.48      0.33        48\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.04      0.10      0.06        81\n",
      "         100       0.17      0.50      0.25       100\n",
      "         101       0.10      0.28      0.14        18\n",
      "         102       0.20      0.33      0.25         3\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.11      0.10      0.11        10\n",
      "         105       0.11      0.33      0.16         6\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.10      0.21      0.13        14\n",
      "         108       0.07      0.05      0.05        22\n",
      "         109       0.07      0.19      0.10        54\n",
      "         110       0.00      0.00      0.00        13\n",
      "         111       0.05      0.08      0.06        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.02      0.06      0.03        33\n",
      "         114       0.18      0.43      0.25       270\n",
      "         115       0.05      0.10      0.07        51\n",
      "         116       0.03      0.12      0.05        34\n",
      "         117       0.00      0.00      0.00         4\n",
      "         118       0.18      0.40      0.25        91\n",
      "         119       0.00      0.00      0.00         5\n",
      "         120       0.00      0.00      0.00        11\n",
      "         121       0.08      0.14      0.10        28\n",
      "         122       0.00      0.00      0.00         9\n",
      "         123       0.41      0.46      0.43       166\n",
      "         124       0.02      0.06      0.03        18\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.00      0.00      0.00        13\n",
      "         127       0.17      0.41      0.24       239\n",
      "         128       0.28      0.67      0.39       276\n",
      "         129       0.00      0.00      0.00         6\n",
      "         130       0.05      0.06      0.05        35\n",
      "         131       0.11      0.31      0.16        13\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         5\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.08      0.28      0.12        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.09      0.18      0.12        67\n",
      "         139       0.20      0.52      0.28       318\n",
      "         140       0.17      0.30      0.21        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.17      0.39      0.24      9022\n",
      "   macro avg       0.07      0.17      0.10      9022\n",
      "weighted avg       0.19      0.39      0.25      9022\n",
      " samples avg       0.17      0.40      0.21      9022\n",
      "\n",
      "Time taken to run this cell : 0:00:05.986177\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs=-1)\n",
    "classifier.fit(x_train_multilabel_ngram,y_train)\n",
    "predictions = classifier.predict (x_test_multilabel_ngram)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = hstack((x_train_multilabel_unigram, x_train_multilabel_bigram, x_train_multilabel_trigram),format=\"csr\",dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1 = hstack((x_test_multilabel_unigram, x_test_multilabel_bigram, x_test_multilabel_trigram),format=\"csr\",dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18712397860903204\n",
      "{'estimator__alpha': 0.001}\n",
      "Time taken to run this cell : 0:01:18.256507\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "start = datetime.now()\n",
    "\n",
    "model = OneVsRestClassifier(SGDClassifier(loss='log', penalty='l2', class_weight=\"balanced\", n_jobs = -1 ), n_jobs = -1)\n",
    "\n",
    "param_grid = {\n",
    "    \"estimator__alpha\": [10**-4,10**-3, 10**-2,10**-1, 10**0, 10**1, 10**2, 10**3, 10**4]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(model, param_grid, scoring='f1_micro',n_jobs=-1)\n",
    "\n",
    "model.fit(x_train_1, y_train)\n",
    "\n",
    "print (model.best_score_)\n",
    "print (model.best_params_)\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.020903573836817263\n",
      "Hamming loss  0.03734341314237414\n",
      "Micro-average quality numbers\n",
      "Precision: 0.2179, Recall: 0.2870, F1-measure: 0.2477\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0793, Recall: 0.0968, F1-measure: 0.0842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        35\n",
      "           1       0.20      0.36      0.26       117\n",
      "           2       0.09      0.04      0.05        26\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.25      0.31      0.28        13\n",
      "           5       0.18      0.12      0.14        26\n",
      "           6       0.00      0.00      0.00        15\n",
      "           7       0.06      0.09      0.07        75\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.05      0.03      0.04        31\n",
      "          10       0.14      0.12      0.13         8\n",
      "          11       0.00      0.00      0.00        20\n",
      "          12       0.06      0.06      0.06        79\n",
      "          13       0.00      0.00      0.00         9\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.00      0.00      0.00        15\n",
      "          16       0.00      0.00      0.00        11\n",
      "          17       0.07      0.09      0.08       120\n",
      "          18       0.15      0.08      0.11        24\n",
      "          19       0.07      0.07      0.07        72\n",
      "          20       0.25      0.40      0.31       351\n",
      "          21       0.00      0.00      0.00        32\n",
      "          22       0.04      0.03      0.03        35\n",
      "          23       0.00      0.00      0.00        29\n",
      "          24       0.03      0.02      0.02        49\n",
      "          25       0.17      0.23      0.20       142\n",
      "          26       0.19      0.15      0.17        65\n",
      "          27       0.00      0.00      0.00        10\n",
      "          28       0.27      0.39      0.32       515\n",
      "          29       0.21      0.32      0.25        90\n",
      "          30       0.21      0.35      0.26        65\n",
      "          31       0.00      0.00      0.00         9\n",
      "          32       0.20      0.19      0.20        21\n",
      "          33       0.07      0.11      0.09        54\n",
      "          34       0.05      0.05      0.05        19\n",
      "          35       0.00      0.00      0.00        26\n",
      "          36       0.23      0.42      0.30        78\n",
      "          37       0.14      0.25      0.18       150\n",
      "          38       0.15      0.13      0.14        82\n",
      "          39       0.00      0.00      0.00        19\n",
      "          40       0.07      0.04      0.05        28\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.02      0.02      0.02        60\n",
      "          43       0.50      0.62      0.56       885\n",
      "          44       0.09      0.11      0.10        66\n",
      "          45       0.20      0.39      0.27       111\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.03      0.03      0.03        38\n",
      "          48       0.05      0.03      0.04        31\n",
      "          49       0.05      0.03      0.04        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.06      0.05      0.05        42\n",
      "          52       0.16      0.27      0.20       229\n",
      "          53       0.06      0.04      0.05        47\n",
      "          54       0.00      0.00      0.00         8\n",
      "          55       0.00      0.00      0.00        24\n",
      "          56       0.20      0.32      0.24       268\n",
      "          57       0.19      0.30      0.23       311\n",
      "          58       0.19      0.23      0.21       142\n",
      "          59       0.12      0.15      0.13       138\n",
      "          60       0.16      0.23      0.19        53\n",
      "          61       0.09      0.08      0.09        49\n",
      "          62       0.05      0.05      0.05        61\n",
      "          63       0.04      0.03      0.03        37\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.12      0.20      0.15       153\n",
      "          66       0.00      0.00      0.00        20\n",
      "          67       0.04      0.04      0.04        52\n",
      "          68       0.39      0.56      0.46       593\n",
      "          69       0.00      0.00      0.00         4\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.00      0.00      0.00        21\n",
      "          72       0.20      0.08      0.12        12\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00        11\n",
      "          75       0.33      0.40      0.36         5\n",
      "          76       0.00      0.00      0.00         9\n",
      "          77       0.38      0.20      0.26        15\n",
      "          78       0.00      0.00      0.00         4\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.00      0.00      0.00        14\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.00      0.00      0.00        20\n",
      "          83       0.00      0.00      0.00        36\n",
      "          84       0.00      0.00      0.00         9\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.14      0.24      0.18       248\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.00      0.00      0.00        25\n",
      "          91       0.09      0.14      0.11       200\n",
      "          92       0.00      0.00      0.00         9\n",
      "          93       0.05      0.06      0.05        50\n",
      "          94       0.00      0.00      0.00        13\n",
      "          95       0.06      0.06      0.06        34\n",
      "          96       0.00      0.00      0.00        17\n",
      "          97       0.28      0.31      0.29        48\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.05      0.04      0.04        81\n",
      "         100       0.18      0.32      0.23       100\n",
      "         101       0.13      0.28      0.18        18\n",
      "         102       0.00      0.00      0.00         3\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.00      0.00      0.00        10\n",
      "         105       0.40      0.33      0.36         6\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.31      0.29      0.30        14\n",
      "         108       0.09      0.05      0.06        22\n",
      "         109       0.12      0.09      0.11        54\n",
      "         110       0.00      0.00      0.00        13\n",
      "         111       0.00      0.00      0.00        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.08      0.06      0.07        33\n",
      "         114       0.19      0.30      0.23       270\n",
      "         115       0.03      0.02      0.02        51\n",
      "         116       0.02      0.03      0.03        34\n",
      "         117       0.00      0.00      0.00         4\n",
      "         118       0.21      0.15      0.18        91\n",
      "         119       0.00      0.00      0.00         5\n",
      "         120       0.00      0.00      0.00        11\n",
      "         121       0.06      0.07      0.07        28\n",
      "         122       0.00      0.00      0.00         9\n",
      "         123       0.44      0.40      0.42       166\n",
      "         124       0.00      0.00      0.00        18\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.00      0.00      0.00        13\n",
      "         127       0.16      0.23      0.19       239\n",
      "         128       0.31      0.60      0.40       276\n",
      "         129       0.00      0.00      0.00         6\n",
      "         130       0.04      0.03      0.03        35\n",
      "         131       0.00      0.00      0.00        13\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         5\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.08      0.15      0.10        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.12      0.10      0.11        67\n",
      "         139       0.18      0.36      0.24       318\n",
      "         140       0.10      0.10      0.10        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.22      0.29      0.25      9022\n",
      "   macro avg       0.08      0.10      0.08      9022\n",
      "weighted avg       0.20      0.29      0.24      9022\n",
      " samples avg       0.20      0.29      0.21      9022\n",
      "\n",
      "Time taken to run this cell : 0:00:06.724518\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs=-1)\n",
    "classifier.fit(x_train_1, y_train)\n",
    "predictions = classifier.predict(x_test_1)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2 = hstack((x_train_multilabel_unigram, x_train_multilabel_bigram, x_train_multilabel_trigram, x_train_multilabel_fourgram),format=\"csr\",dtype='float64')\n",
    "x_test_2 = hstack((x_test_multilabel_unigram, x_test_multilabel_bigram, x_test_multilabel_trigram, x_test_multilabel_fourgram),format=\"csr\",dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19961240026772956\n",
      "{'estimator__alpha': 0.001}\n",
      "Time taken to run this cell : 0:01:09.366789\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "model = OneVsRestClassifier(SGDClassifier(loss='log', penalty='l2', class_weight=\"balanced\", n_jobs = -1 ), n_jobs = -1)\n",
    "\n",
    "param_grid = {\n",
    "    \"estimator__alpha\": [10**-4,10**-3, 10**-2,10**-1, 10**0, 10**1, 10**2, 10**3, 10**4]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(model, param_grid, scoring='f1_micro',n_jobs=-1)\n",
    "\n",
    "model.fit(x_train_2, y_train)\n",
    "\n",
    "print (model.best_score_)\n",
    "print (model.best_params_)\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.02191503708698584\n",
      "Hamming loss  0.037549979580788845\n",
      "Micro-average quality numbers\n",
      "Precision: 0.2165, Recall: 0.2875, F1-measure: 0.2470\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0844, Recall: 0.0979, F1-measure: 0.0849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        35\n",
      "           1       0.20      0.34      0.25       117\n",
      "           2       0.08      0.04      0.05        26\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.16      0.23      0.19        13\n",
      "           5       0.21      0.15      0.18        26\n",
      "           6       0.00      0.00      0.00        15\n",
      "           7       0.06      0.09      0.07        75\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.05      0.03      0.04        31\n",
      "          10       0.11      0.12      0.12         8\n",
      "          11       0.00      0.00      0.00        20\n",
      "          12       0.05      0.06      0.06        79\n",
      "          13       0.00      0.00      0.00         9\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.00      0.00      0.00        15\n",
      "          16       0.00      0.00      0.00        11\n",
      "          17       0.07      0.10      0.09       120\n",
      "          18       0.17      0.08      0.11        24\n",
      "          19       0.07      0.07      0.07        72\n",
      "          20       0.25      0.41      0.31       351\n",
      "          21       0.06      0.03      0.04        32\n",
      "          22       0.04      0.03      0.03        35\n",
      "          23       0.00      0.00      0.00        29\n",
      "          24       0.03      0.02      0.02        49\n",
      "          25       0.18      0.23      0.20       142\n",
      "          26       0.18      0.15      0.17        65\n",
      "          27       0.00      0.00      0.00        10\n",
      "          28       0.27      0.38      0.32       515\n",
      "          29       0.21      0.33      0.26        90\n",
      "          30       0.21      0.34      0.26        65\n",
      "          31       0.00      0.00      0.00         9\n",
      "          32       0.16      0.14      0.15        21\n",
      "          33       0.08      0.11      0.09        54\n",
      "          34       0.05      0.05      0.05        19\n",
      "          35       0.00      0.00      0.00        26\n",
      "          36       0.23      0.45      0.31        78\n",
      "          37       0.14      0.24      0.18       150\n",
      "          38       0.15      0.15      0.15        82\n",
      "          39       0.00      0.00      0.00        19\n",
      "          40       0.07      0.04      0.05        28\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.02      0.02      0.02        60\n",
      "          43       0.50      0.62      0.56       885\n",
      "          44       0.11      0.12      0.11        66\n",
      "          45       0.20      0.38      0.26       111\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.03      0.03      0.03        38\n",
      "          48       0.04      0.03      0.04        31\n",
      "          49       0.04      0.03      0.04        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.06      0.05      0.05        42\n",
      "          52       0.17      0.27      0.21       229\n",
      "          53       0.05      0.04      0.05        47\n",
      "          54       0.00      0.00      0.00         8\n",
      "          55       0.00      0.00      0.00        24\n",
      "          56       0.19      0.32      0.24       268\n",
      "          57       0.19      0.28      0.23       311\n",
      "          58       0.19      0.23      0.21       142\n",
      "          59       0.13      0.18      0.15       138\n",
      "          60       0.16      0.21      0.18        53\n",
      "          61       0.11      0.10      0.11        49\n",
      "          62       0.05      0.05      0.05        61\n",
      "          63       0.04      0.03      0.03        37\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.12      0.19      0.15       153\n",
      "          66       0.00      0.00      0.00        20\n",
      "          67       0.03      0.04      0.03        52\n",
      "          68       0.39      0.55      0.46       593\n",
      "          69       0.00      0.00      0.00         4\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.00      0.00      0.00        21\n",
      "          72       0.14      0.08      0.11        12\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00        11\n",
      "          75       0.29      0.40      0.33         5\n",
      "          76       1.00      0.11      0.20         9\n",
      "          77       0.30      0.20      0.24        15\n",
      "          78       0.00      0.00      0.00         4\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.00      0.00      0.00        14\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.00      0.00      0.00        20\n",
      "          83       0.00      0.00      0.00        36\n",
      "          84       0.00      0.00      0.00         9\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.14      0.23      0.17       248\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.00      0.00      0.00        25\n",
      "          91       0.09      0.14      0.11       200\n",
      "          92       0.00      0.00      0.00         9\n",
      "          93       0.05      0.06      0.05        50\n",
      "          94       0.00      0.00      0.00        13\n",
      "          95       0.07      0.06      0.06        34\n",
      "          96       0.00      0.00      0.00        17\n",
      "          97       0.27      0.31      0.29        48\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.05      0.04      0.04        81\n",
      "         100       0.18      0.32      0.23       100\n",
      "         101       0.11      0.28      0.16        18\n",
      "         102       0.00      0.00      0.00         3\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.00      0.00      0.00        10\n",
      "         105       0.33      0.33      0.33         6\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.31      0.29      0.30        14\n",
      "         108       0.11      0.05      0.06        22\n",
      "         109       0.12      0.09      0.10        54\n",
      "         110       0.00      0.00      0.00        13\n",
      "         111       0.00      0.00      0.00        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.08      0.06      0.07        33\n",
      "         114       0.19      0.31      0.24       270\n",
      "         115       0.00      0.00      0.00        51\n",
      "         116       0.02      0.03      0.02        34\n",
      "         117       0.00      0.00      0.00         4\n",
      "         118       0.19      0.15      0.17        91\n",
      "         119       0.00      0.00      0.00         5\n",
      "         120       0.00      0.00      0.00        11\n",
      "         121       0.08      0.11      0.09        28\n",
      "         122       0.00      0.00      0.00         9\n",
      "         123       0.46      0.40      0.43       166\n",
      "         124       0.00      0.00      0.00        18\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.00      0.00      0.00        13\n",
      "         127       0.16      0.23      0.19       239\n",
      "         128       0.30      0.61      0.40       276\n",
      "         129       0.00      0.00      0.00         6\n",
      "         130       0.08      0.06      0.07        35\n",
      "         131       0.00      0.00      0.00        13\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         5\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.09      0.15      0.11        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.12      0.12      0.12        67\n",
      "         139       0.18      0.36      0.24       318\n",
      "         140       0.12      0.10      0.11        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.22      0.29      0.25      9022\n",
      "   macro avg       0.08      0.10      0.08      9022\n",
      "weighted avg       0.20      0.29      0.24      9022\n",
      " samples avg       0.21      0.29      0.21      9022\n",
      "\n",
      "Time taken to run this cell : 0:00:06.572685\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs=-1)\n",
    "classifier.fit(x_train_2, y_train)\n",
    "predictions = classifier.predict(x_test_2)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_glove = np.load('glove_tarin.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_glove = np.load('glove_test.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2 = hstack((x_train_multilabel_unigram, x_train_multilabel_bigram, x_train_multilabel_trigram, x_train_multilabel_fourgram),format=\"csr\",dtype='float64')\n",
    "x_test_2 = hstack((x_test_multilabel_unigram, x_test_multilabel_bigram, x_test_multilabel_trigram, x_test_multilabel_fourgram),format=\"csr\",dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2 = x_train_2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9489, 40857)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_2 = x_test_2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2966, 40857)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9489, 300)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2966, 300)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_3 = np.hstack((x_train_2, train_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9489, 41157)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_3 = np.hstack((x_test_2, test_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2966, 41157)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('gove+train2_for_every_feature.npy', x_train_3)\n",
    "np.save('gove+test2_for_every_feature.npy', x_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.009440323668240054\n",
      "Hamming loss  0.0726781457456811\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1803, Recall: 0.6750, F1-measure: 0.2846\n",
      "Macro-average quality numbers\n",
      "Precision: 0.1655, Recall: 0.6215, F1-measure: 0.2297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.49      0.10        35\n",
      "           1       0.21      0.62      0.32       117\n",
      "           2       0.87      1.00      0.93        26\n",
      "           3       0.02      0.27      0.03        11\n",
      "           4       0.11      0.85      0.20        13\n",
      "           5       0.19      1.00      0.32        26\n",
      "           6       0.14      1.00      0.24        15\n",
      "           7       0.10      0.72      0.17        75\n",
      "           8       0.02      0.25      0.03         4\n",
      "           9       0.32      1.00      0.49        31\n",
      "          10       0.29      0.88      0.44         8\n",
      "          11       0.04      0.50      0.07        20\n",
      "          12       0.12      0.47      0.19        79\n",
      "          13       0.04      0.44      0.07         9\n",
      "          14       0.02      1.00      0.04         3\n",
      "          15       0.04      0.47      0.08        15\n",
      "          16       0.05      0.45      0.09        11\n",
      "          17       0.14      0.36      0.20       120\n",
      "          18       0.13      0.58      0.22        24\n",
      "          19       0.10      0.49      0.16        72\n",
      "          20       0.31      0.70      0.42       351\n",
      "          21       0.12      0.56      0.19        32\n",
      "          22       0.04      0.17      0.07        35\n",
      "          23       0.04      0.14      0.06        29\n",
      "          24       0.09      0.49      0.16        49\n",
      "          25       0.49      0.74      0.59       142\n",
      "          26       0.12      0.63      0.21        65\n",
      "          27       0.07      0.40      0.11        10\n",
      "          28       0.63      0.82      0.71       515\n",
      "          29       0.51      1.00      0.67        90\n",
      "          30       0.10      0.49      0.17        65\n",
      "          31       0.08      1.00      0.15         9\n",
      "          32       0.06      0.57      0.10        21\n",
      "          33       0.21      0.65      0.31        54\n",
      "          34       0.23      0.95      0.38        19\n",
      "          35       0.84      1.00      0.91        26\n",
      "          36       0.13      0.71      0.22        78\n",
      "          37       0.20      0.63      0.30       150\n",
      "          38       0.11      0.72      0.19        82\n",
      "          39       0.05      0.26      0.08        19\n",
      "          40       0.03      0.18      0.06        28\n",
      "          41       0.14      1.00      0.25         5\n",
      "          42       0.40      0.72      0.51        60\n",
      "          43       0.53      0.80      0.64       885\n",
      "          44       0.10      0.58      0.17        66\n",
      "          45       0.51      1.00      0.67       111\n",
      "          46       0.01      1.00      0.02         1\n",
      "          47       0.08      0.68      0.14        38\n",
      "          48       0.08      0.39      0.13        31\n",
      "          49       0.33      0.97      0.49        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.83      0.93      0.88        42\n",
      "          52       0.21      0.56      0.31       229\n",
      "          53       0.05      0.30      0.08        47\n",
      "          54       0.18      1.00      0.30         8\n",
      "          55       0.04      0.58      0.08        24\n",
      "          56       0.33      0.78      0.46       268\n",
      "          57       0.30      0.77      0.43       311\n",
      "          58       0.64      0.82      0.72       142\n",
      "          59       0.23      0.54      0.32       138\n",
      "          60       0.75      0.92      0.83        53\n",
      "          61       0.88      0.73      0.80        49\n",
      "          62       0.14      0.75      0.24        61\n",
      "          63       0.07      0.57      0.13        37\n",
      "          64       0.05      0.50      0.08         6\n",
      "          65       0.20      0.59      0.30       153\n",
      "          66       0.06      0.30      0.10        20\n",
      "          67       0.08      0.79      0.15        52\n",
      "          68       0.50      0.77      0.61       593\n",
      "          69       0.01      0.25      0.01         4\n",
      "          70       0.01      0.17      0.01         6\n",
      "          71       0.05      0.29      0.09        21\n",
      "          72       0.24      0.83      0.38        12\n",
      "          73       0.07      1.00      0.14         2\n",
      "          74       0.02      0.27      0.04        11\n",
      "          75       0.15      1.00      0.26         5\n",
      "          76       0.15      0.89      0.25         9\n",
      "          77       0.22      0.93      0.35        15\n",
      "          78       0.00      0.75      0.01         4\n",
      "          79       0.67      0.50      0.57         4\n",
      "          80       0.11      1.00      0.20        14\n",
      "          81       0.00      0.33      0.01         3\n",
      "          82       0.06      0.35      0.10        20\n",
      "          83       0.04      0.36      0.08        36\n",
      "          84       0.01      0.11      0.02         9\n",
      "          85       0.03      1.00      0.06         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.24      0.67      0.35       248\n",
      "          89       0.07      0.67      0.13         3\n",
      "          90       0.10      0.64      0.17        25\n",
      "          91       0.22      0.44      0.29       200\n",
      "          92       0.04      0.67      0.07         9\n",
      "          93       0.08      0.54      0.13        50\n",
      "          94       0.05      0.23      0.08        13\n",
      "          95       0.05      0.24      0.08        34\n",
      "          96       0.04      0.41      0.08        17\n",
      "          97       0.15      0.60      0.23        48\n",
      "          98       0.00      1.00      0.00         1\n",
      "          99       0.20      0.95      0.33        81\n",
      "         100       0.49      1.00      0.65       100\n",
      "         101       0.05      0.67      0.10        18\n",
      "         102       0.01      1.00      0.03         3\n",
      "         103       0.03      1.00      0.06         5\n",
      "         104       0.09      0.70      0.15        10\n",
      "         105       0.32      1.00      0.48         6\n",
      "         106       0.03      1.00      0.05         3\n",
      "         107       0.02      0.71      0.04        14\n",
      "         108       0.15      0.77      0.26        22\n",
      "         109       0.07      0.11      0.09        54\n",
      "         110       0.03      0.46      0.06        13\n",
      "         111       0.04      0.25      0.07        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.22      0.61      0.32        33\n",
      "         114       0.42      0.73      0.53       270\n",
      "         115       0.11      0.41      0.17        51\n",
      "         116       0.24      0.91      0.38        34\n",
      "         117       0.15      1.00      0.26         4\n",
      "         118       0.34      0.34      0.34        91\n",
      "         119       0.06      0.80      0.12         5\n",
      "         120       0.09      0.64      0.16        11\n",
      "         121       0.07      0.50      0.12        28\n",
      "         122       0.16      0.89      0.27         9\n",
      "         123       0.37      0.70      0.48       166\n",
      "         124       0.03      0.28      0.06        18\n",
      "         125       0.03      0.86      0.05         7\n",
      "         126       0.07      0.15      0.10        13\n",
      "         127       0.20      0.49      0.28       239\n",
      "         128       0.22      0.80      0.35       276\n",
      "         129       0.01      0.67      0.02         6\n",
      "         130       0.23      0.74      0.35        35\n",
      "         131       0.20      0.92      0.33        13\n",
      "         132       0.01      1.00      0.02         2\n",
      "         133       0.13      0.80      0.22         5\n",
      "         134       0.01      0.50      0.02         2\n",
      "         135       0.01      1.00      0.01         2\n",
      "         136       0.07      0.49      0.13        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.08      0.40      0.14        67\n",
      "         139       0.31      0.50      0.38       318\n",
      "         140       0.08      0.20      0.11        10\n",
      "         141       0.01      0.14      0.01         7\n",
      "\n",
      "   micro avg       0.18      0.68      0.28      9022\n",
      "   macro avg       0.17      0.62      0.23      9022\n",
      "weighted avg       0.32      0.68      0.41      9022\n",
      " samples avg       0.26      0.75      0.35      9022\n",
      "\n",
      "Time taken to run this cell : 0:36:02.872583\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs=-1)\n",
    "classifier.fit(x_train_3, y_train)\n",
    "predictions = classifier.predict(x_test_3)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.0\n",
      "Hamming loss  0.08203774230005793\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1569, Recall: 0.6471, F1-measure: 0.2526\n",
      "Macro-average quality numbers\n",
      "Precision: 0.1789, Recall: 0.5978, F1-measure: 0.2350\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.17      0.08        35\n",
      "           1       0.33      0.50      0.40       117\n",
      "           2       0.93      1.00      0.96        26\n",
      "           3       0.01      0.18      0.02        11\n",
      "           4       0.16      0.69      0.26        13\n",
      "           5       0.33      1.00      0.49        26\n",
      "           6       0.11      0.93      0.20        15\n",
      "           7       0.13      0.67      0.21        75\n",
      "           8       0.00      0.25      0.01         4\n",
      "           9       0.53      1.00      0.70        31\n",
      "          10       0.09      0.75      0.16         8\n",
      "          11       0.00      0.00      0.00        20\n",
      "          12       0.13      0.42      0.20        79\n",
      "          13       0.02      0.44      0.04         9\n",
      "          14       0.01      1.00      0.03         3\n",
      "          15       0.03      0.73      0.06        15\n",
      "          16       0.03      0.64      0.06        11\n",
      "          17       0.15      0.33      0.20       120\n",
      "          18       0.60      0.50      0.55        24\n",
      "          19       0.15      0.29      0.20        72\n",
      "          20       0.34      0.64      0.45       351\n",
      "          21       0.03      0.59      0.06        32\n",
      "          22       0.03      0.23      0.05        35\n",
      "          23       0.05      0.31      0.09        29\n",
      "          24       0.06      0.59      0.10        49\n",
      "          25       0.63      0.72      0.67       142\n",
      "          26       0.15      0.51      0.23        65\n",
      "          27       0.03      0.40      0.05        10\n",
      "          28       0.55      0.89      0.68       515\n",
      "          29       0.62      0.99      0.76        90\n",
      "          30       0.16      0.37      0.22        65\n",
      "          31       0.09      1.00      0.17         9\n",
      "          32       0.08      0.52      0.14        21\n",
      "          33       0.21      0.67      0.32        54\n",
      "          34       0.25      0.79      0.38        19\n",
      "          35       0.84      1.00      0.91        26\n",
      "          36       0.20      0.72      0.32        78\n",
      "          37       0.23      0.53      0.32       150\n",
      "          38       0.19      0.39      0.25        82\n",
      "          39       0.03      0.26      0.05        19\n",
      "          40       0.12      0.29      0.17        28\n",
      "          41       0.06      1.00      0.11         5\n",
      "          42       0.56      0.67      0.61        60\n",
      "          43       0.53      0.79      0.64       885\n",
      "          44       0.14      0.47      0.21        66\n",
      "          45       0.67      0.96      0.79       111\n",
      "          46       0.00      1.00      0.01         1\n",
      "          47       0.11      0.61      0.19        38\n",
      "          48       0.06      0.35      0.11        31\n",
      "          49       0.57      0.76      0.65        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.55      0.93      0.69        42\n",
      "          52       0.22      0.51      0.30       229\n",
      "          53       0.12      0.15      0.14        47\n",
      "          54       0.15      1.00      0.26         8\n",
      "          55       0.02      0.50      0.05        24\n",
      "          56       0.37      0.72      0.49       268\n",
      "          57       0.26      0.82      0.40       311\n",
      "          58       0.61      0.82      0.70       142\n",
      "          59       0.27      0.44      0.33       138\n",
      "          60       0.80      0.92      0.86        53\n",
      "          61       0.88      0.71      0.79        49\n",
      "          62       0.43      0.54      0.48        61\n",
      "          63       0.11      0.32      0.17        37\n",
      "          64       0.01      0.50      0.01         6\n",
      "          65       0.25      0.58      0.35       153\n",
      "          66       0.02      0.15      0.03        20\n",
      "          67       0.11      0.52      0.18        52\n",
      "          68       0.53      0.76      0.63       593\n",
      "          69       0.00      0.25      0.00         4\n",
      "          70       0.01      0.17      0.01         6\n",
      "          71       0.03      0.38      0.05        21\n",
      "          72       0.09      0.75      0.16        12\n",
      "          73       0.05      1.00      0.10         2\n",
      "          74       0.03      0.27      0.05        11\n",
      "          75       0.06      0.80      0.11         5\n",
      "          76       0.08      0.89      0.14         9\n",
      "          77       0.30      0.93      0.45        15\n",
      "          78       0.01      0.75      0.02         4\n",
      "          79       0.03      0.50      0.05         4\n",
      "          80       0.15      0.93      0.26        14\n",
      "          81       0.00      0.33      0.01         3\n",
      "          82       0.11      0.30      0.16        20\n",
      "          83       0.03      0.28      0.06        36\n",
      "          84       0.00      0.11      0.01         9\n",
      "          85       0.04      1.00      0.07         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.28      0.53      0.37       248\n",
      "          89       0.12      0.67      0.21         3\n",
      "          90       0.15      0.60      0.24        25\n",
      "          91       0.22      0.39      0.28       200\n",
      "          92       0.04      0.67      0.07         9\n",
      "          93       0.06      0.20      0.09        50\n",
      "          94       0.07      0.38      0.12        13\n",
      "          95       0.05      0.21      0.08        34\n",
      "          96       0.03      0.41      0.06        17\n",
      "          97       0.30      0.50      0.38        48\n",
      "          98       0.00      1.00      0.00         1\n",
      "          99       0.20      0.95      0.34        81\n",
      "         100       0.58      0.99      0.73       100\n",
      "         101       0.08      0.33      0.13        18\n",
      "         102       0.01      1.00      0.02         3\n",
      "         103       0.33      1.00      0.50         5\n",
      "         104       0.03      0.70      0.05        10\n",
      "         105       0.05      1.00      0.09         6\n",
      "         106       0.03      1.00      0.05         3\n",
      "         107       0.08      0.50      0.13        14\n",
      "         108       0.23      0.73      0.34        22\n",
      "         109       0.08      0.15      0.11        54\n",
      "         110       0.04      0.62      0.07        13\n",
      "         111       0.01      0.58      0.02        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.33      0.61      0.43        33\n",
      "         114       0.43      0.74      0.55       270\n",
      "         115       0.10      0.16      0.12        51\n",
      "         116       0.26      0.88      0.40        34\n",
      "         117       0.22      1.00      0.36         4\n",
      "         118       0.51      0.33      0.40        91\n",
      "         119       0.02      0.80      0.04         5\n",
      "         120       0.18      0.91      0.30        11\n",
      "         121       0.06      0.39      0.10        28\n",
      "         122       0.16      0.89      0.28         9\n",
      "         123       0.44      0.67      0.53       166\n",
      "         124       0.03      0.17      0.05        18\n",
      "         125       0.02      0.86      0.05         7\n",
      "         126       0.03      0.31      0.05        13\n",
      "         127       0.18      0.52      0.27       239\n",
      "         128       0.36      0.70      0.48       276\n",
      "         129       0.01      0.67      0.01         6\n",
      "         130       0.10      0.74      0.18        35\n",
      "         131       0.33      0.92      0.49        13\n",
      "         132       0.01      1.00      0.01         2\n",
      "         133       0.02      0.80      0.03         5\n",
      "         134       0.00      1.00      0.01         2\n",
      "         135       0.01      1.00      0.02         2\n",
      "         136       0.09      0.63      0.16        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.05      0.67      0.09        67\n",
      "         139       0.27      0.64      0.38       318\n",
      "         140       0.01      0.60      0.03        10\n",
      "         141       0.00      0.14      0.00         7\n",
      "\n",
      "   micro avg       0.16      0.65      0.25      9022\n",
      "   macro avg       0.18      0.60      0.24      9022\n",
      "weighted avg       0.34      0.65      0.43      9022\n",
      " samples avg       0.19      0.75      0.28      9022\n",
      "\n",
      "Time taken to run this cell : 0:22:30.264912\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='hinge', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs = -1)\n",
    "classifier.fit(x_train_3, y_train)\n",
    "predictions = classifier.predict(x_test_3)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = x_train_1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1 = x_test_1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_4 = np.hstack((x_train_1, train_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_4 = np.hstack((x_test_1, test_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('gove+train1_for_every_feature.npy', x_train_4)\n",
    "np.save('gove+test1_for_every_feature.npy', x_test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.009103169251517195\n",
      "Hamming loss  0.07314588814071211\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1795, Recall: 0.6759, F1-measure: 0.2836\n",
      "Macro-average quality numbers\n",
      "Precision: 0.1697, Recall: 0.6251, F1-measure: 0.2363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.63      0.11        35\n",
      "           1       0.18      0.73      0.29       117\n",
      "           2       0.43      1.00      0.60        26\n",
      "           3       0.02      0.27      0.03        11\n",
      "           4       0.12      0.77      0.21        13\n",
      "           5       0.19      1.00      0.31        26\n",
      "           6       0.07      0.80      0.12        15\n",
      "           7       0.11      0.76      0.19        75\n",
      "           8       0.01      0.25      0.02         4\n",
      "           9       0.25      1.00      0.41        31\n",
      "          10       0.30      0.75      0.43         8\n",
      "          11       0.02      0.60      0.04        20\n",
      "          12       0.09      0.66      0.15        79\n",
      "          13       0.04      0.56      0.07         9\n",
      "          14       0.03      1.00      0.06         3\n",
      "          15       0.04      0.40      0.07        15\n",
      "          16       0.03      0.64      0.06        11\n",
      "          17       0.14      0.39      0.21       120\n",
      "          18       0.20      0.54      0.29        24\n",
      "          19       0.15      0.38      0.22        72\n",
      "          20       0.31      0.67      0.43       351\n",
      "          21       0.10      0.56      0.17        32\n",
      "          22       0.03      0.20      0.05        35\n",
      "          23       0.06      0.14      0.08        29\n",
      "          24       0.07      0.57      0.13        49\n",
      "          25       0.57      0.73      0.64       142\n",
      "          26       0.16      0.52      0.24        65\n",
      "          27       0.03      0.40      0.06        10\n",
      "          28       0.55      0.87      0.68       515\n",
      "          29       0.51      1.00      0.67        90\n",
      "          30       0.10      0.45      0.16        65\n",
      "          31       0.23      0.89      0.36         9\n",
      "          32       0.04      0.52      0.08        21\n",
      "          33       0.22      0.63      0.32        54\n",
      "          34       0.23      0.95      0.36        19\n",
      "          35       0.87      1.00      0.93        26\n",
      "          36       0.15      0.65      0.25        78\n",
      "          37       0.18      0.65      0.28       150\n",
      "          38       0.12      0.70      0.21        82\n",
      "          39       0.04      0.26      0.07        19\n",
      "          40       0.03      0.18      0.06        28\n",
      "          41       0.06      1.00      0.11         5\n",
      "          42       0.32      0.72      0.44        60\n",
      "          43       0.58      0.69      0.63       885\n",
      "          44       0.10      0.61      0.17        66\n",
      "          45       0.54      1.00      0.70       111\n",
      "          46       0.01      1.00      0.02         1\n",
      "          47       0.08      0.68      0.14        38\n",
      "          48       0.04      0.48      0.08        31\n",
      "          49       0.27      0.97      0.43        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.68      0.93      0.79        42\n",
      "          52       0.20      0.68      0.31       229\n",
      "          53       0.04      0.28      0.08        47\n",
      "          54       0.15      0.88      0.25         8\n",
      "          55       0.04      0.54      0.08        24\n",
      "          56       0.35      0.75      0.47       268\n",
      "          57       0.29      0.75      0.42       311\n",
      "          58       0.84      0.82      0.83       142\n",
      "          59       0.24      0.56      0.34       138\n",
      "          60       0.79      0.92      0.85        53\n",
      "          61       0.86      0.73      0.79        49\n",
      "          62       0.34      0.61      0.44        61\n",
      "          63       0.07      0.62      0.13        37\n",
      "          64       0.04      0.50      0.07         6\n",
      "          65       0.20      0.60      0.30       153\n",
      "          66       0.04      0.40      0.08        20\n",
      "          67       0.12      0.69      0.20        52\n",
      "          68       0.54      0.74      0.63       593\n",
      "          69       0.01      0.25      0.02         4\n",
      "          70       0.02      0.17      0.04         6\n",
      "          71       0.05      0.43      0.09        21\n",
      "          72       0.11      0.75      0.19        12\n",
      "          73       0.08      1.00      0.14         2\n",
      "          74       0.02      0.27      0.03        11\n",
      "          75       0.33      1.00      0.50         5\n",
      "          76       0.13      0.89      0.23         9\n",
      "          77       0.28      0.93      0.43        15\n",
      "          78       0.00      0.75      0.01         4\n",
      "          79       0.05      0.50      0.08         4\n",
      "          80       0.11      1.00      0.20        14\n",
      "          81       0.00      0.33      0.01         3\n",
      "          82       0.17      0.35      0.23        20\n",
      "          83       0.05      0.36      0.10        36\n",
      "          84       0.01      0.11      0.02         9\n",
      "          85       0.05      1.00      0.10         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.22      0.74      0.34       248\n",
      "          89       0.01      0.67      0.02         3\n",
      "          90       0.11      0.60      0.19        25\n",
      "          91       0.20      0.46      0.28       200\n",
      "          92       0.03      0.67      0.06         9\n",
      "          93       0.06      0.58      0.12        50\n",
      "          94       0.02      0.62      0.03        13\n",
      "          95       0.04      0.21      0.06        34\n",
      "          96       0.04      0.41      0.08        17\n",
      "          97       0.18      0.62      0.28        48\n",
      "          98       0.00      1.00      0.01         1\n",
      "          99       0.20      0.95      0.33        81\n",
      "         100       0.49      1.00      0.65       100\n",
      "         101       0.06      0.67      0.11        18\n",
      "         102       0.12      1.00      0.21         3\n",
      "         103       0.38      1.00      0.56         5\n",
      "         104       0.11      0.70      0.19        10\n",
      "         105       0.33      1.00      0.50         6\n",
      "         106       0.12      1.00      0.22         3\n",
      "         107       0.03      0.57      0.06        14\n",
      "         108       0.14      0.68      0.23        22\n",
      "         109       0.04      0.35      0.07        54\n",
      "         110       0.06      0.46      0.11        13\n",
      "         111       0.05      0.25      0.08        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.32      0.61      0.42        33\n",
      "         114       0.36      0.78      0.50       270\n",
      "         115       0.04      0.49      0.07        51\n",
      "         116       0.24      0.97      0.39        34\n",
      "         117       0.09      1.00      0.16         4\n",
      "         118       0.36      0.34      0.35        91\n",
      "         119       0.07      0.80      0.13         5\n",
      "         120       0.24      0.73      0.36        11\n",
      "         121       0.11      0.43      0.18        28\n",
      "         122       0.15      0.89      0.25         9\n",
      "         123       0.53      0.65      0.59       166\n",
      "         124       0.03      0.17      0.05        18\n",
      "         125       0.07      0.86      0.13         7\n",
      "         126       0.04      0.31      0.07        13\n",
      "         127       0.16      0.68      0.26       239\n",
      "         128       0.46      0.57      0.51       276\n",
      "         129       0.01      0.67      0.03         6\n",
      "         130       0.41      0.74      0.53        35\n",
      "         131       0.33      0.92      0.49        13\n",
      "         132       0.05      1.00      0.09         2\n",
      "         133       0.08      0.80      0.15         5\n",
      "         134       0.01      0.50      0.03         2\n",
      "         135       0.01      1.00      0.03         2\n",
      "         136       0.11      0.40      0.17        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.10      0.36      0.16        67\n",
      "         139       0.23      0.71      0.35       318\n",
      "         140       0.03      0.30      0.05        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.18      0.68      0.28      9022\n",
      "   macro avg       0.17      0.63      0.24      9022\n",
      "weighted avg       0.33      0.68      0.41      9022\n",
      " samples avg       0.23      0.76      0.33      9022\n",
      "\n",
      "Time taken to run this cell : 0:33:41.300593\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs = -1)\n",
    "classifier.fit(x_train_4, y_train)\n",
    "predictions = classifier.predict(x_test_4)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.008766014834794335\n",
      "Hamming loss  0.0738344429354278\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1736, Recall: 0.6505, F1-measure: 0.2740\n",
      "Macro-average quality numbers\n",
      "Precision: 0.1951, Recall: 0.6011, F1-measure: 0.2510\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.63      0.09        35\n",
      "           1       0.19      0.70      0.30       117\n",
      "           2       0.90      1.00      0.95        26\n",
      "           3       0.01      0.36      0.02        11\n",
      "           4       0.14      0.77      0.23        13\n",
      "           5       0.33      1.00      0.50        26\n",
      "           6       0.09      0.67      0.16        15\n",
      "           7       0.19      0.47      0.27        75\n",
      "           8       0.03      0.25      0.05         4\n",
      "           9       0.59      0.97      0.73        31\n",
      "          10       0.88      0.88      0.88         8\n",
      "          11       0.01      0.10      0.03        20\n",
      "          12       0.13      0.46      0.21        79\n",
      "          13       0.02      0.56      0.04         9\n",
      "          14       0.02      1.00      0.04         3\n",
      "          15       0.04      0.47      0.08        15\n",
      "          16       0.03      0.64      0.06        11\n",
      "          17       0.14      0.33      0.19       120\n",
      "          18       0.33      0.54      0.41        24\n",
      "          19       0.15      0.35      0.21        72\n",
      "          20       0.35      0.62      0.45       351\n",
      "          21       0.07      0.59      0.13        32\n",
      "          22       0.08      0.17      0.11        35\n",
      "          23       0.10      0.14      0.11        29\n",
      "          24       0.16      0.31      0.21        49\n",
      "          25       0.66      0.68      0.67       142\n",
      "          26       0.34      0.37      0.35        65\n",
      "          27       0.03      0.40      0.05        10\n",
      "          28       0.59      0.83      0.69       515\n",
      "          29       0.62      0.99      0.76        90\n",
      "          30       0.19      0.37      0.25        65\n",
      "          31       0.15      0.89      0.25         9\n",
      "          32       0.05      0.57      0.08        21\n",
      "          33       0.08      0.72      0.14        54\n",
      "          34       0.31      0.89      0.46        19\n",
      "          35       0.87      1.00      0.93        26\n",
      "          36       0.17      0.69      0.28        78\n",
      "          37       0.22      0.59      0.32       150\n",
      "          38       0.14      0.51      0.22        82\n",
      "          39       0.03      0.42      0.06        19\n",
      "          40       0.02      0.29      0.03        28\n",
      "          41       0.08      1.00      0.15         5\n",
      "          42       0.39      0.72      0.51        60\n",
      "          43       0.55      0.79      0.65       885\n",
      "          44       0.16      0.24      0.20        66\n",
      "          45       0.67      0.99      0.80       111\n",
      "          46       0.01      1.00      0.02         1\n",
      "          47       0.13      0.42      0.20        38\n",
      "          48       0.05      0.39      0.09        31\n",
      "          49       0.45      0.88      0.59        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.83      0.90      0.86        42\n",
      "          52       0.18      0.60      0.27       229\n",
      "          53       0.14      0.26      0.18        47\n",
      "          54       0.35      0.88      0.50         8\n",
      "          55       0.05      0.25      0.08        24\n",
      "          56       0.42      0.70      0.52       268\n",
      "          57       0.32      0.71      0.44       311\n",
      "          58       0.90      0.78      0.84       142\n",
      "          59       0.30      0.47      0.36       138\n",
      "          60       0.80      0.92      0.86        53\n",
      "          61       0.77      0.69      0.73        49\n",
      "          62       0.44      0.59      0.51        61\n",
      "          63       0.12      0.41      0.19        37\n",
      "          64       0.01      0.50      0.01         6\n",
      "          65       0.15      0.62      0.25       153\n",
      "          66       0.04      0.30      0.07        20\n",
      "          67       0.11      0.67      0.18        52\n",
      "          68       0.50      0.81      0.61       593\n",
      "          69       0.00      0.25      0.00         4\n",
      "          70       0.02      0.17      0.04         6\n",
      "          71       0.06      0.29      0.10        21\n",
      "          72       0.24      0.75      0.37        12\n",
      "          73       0.03      1.00      0.05         2\n",
      "          74       0.06      0.27      0.10        11\n",
      "          75       0.04      0.80      0.07         5\n",
      "          76       0.07      0.78      0.12         9\n",
      "          77       0.25      0.93      0.40        15\n",
      "          78       0.01      1.00      0.01         4\n",
      "          79       0.67      0.50      0.57         4\n",
      "          80       0.15      0.93      0.26        14\n",
      "          81       0.00      0.33      0.01         3\n",
      "          82       0.08      0.25      0.12        20\n",
      "          83       0.09      0.25      0.13        36\n",
      "          84       0.06      0.11      0.08         9\n",
      "          85       0.04      1.00      0.08         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.50      0.00         2\n",
      "          88       0.25      0.61      0.35       248\n",
      "          89       0.14      0.67      0.24         3\n",
      "          90       0.08      0.64      0.14        25\n",
      "          91       0.17      0.51      0.25       200\n",
      "          92       0.02      0.67      0.04         9\n",
      "          93       0.09      0.12      0.10        50\n",
      "          94       0.04      0.46      0.07        13\n",
      "          95       0.08      0.18      0.11        34\n",
      "          96       0.01      0.53      0.03        17\n",
      "          97       0.19      0.50      0.28        48\n",
      "          98       0.01      1.00      0.01         1\n",
      "          99       0.20      0.94      0.33        81\n",
      "         100       0.55      0.99      0.70       100\n",
      "         101       0.08      0.33      0.13        18\n",
      "         102       0.03      1.00      0.05         3\n",
      "         103       0.33      1.00      0.50         5\n",
      "         104       0.09      0.70      0.16        10\n",
      "         105       0.12      1.00      0.21         6\n",
      "         106       0.05      1.00      0.10         3\n",
      "         107       0.20      0.50      0.29        14\n",
      "         108       0.09      0.77      0.16        22\n",
      "         109       0.04      0.41      0.07        54\n",
      "         110       0.06      0.46      0.11        13\n",
      "         111       0.06      0.25      0.09        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.18      0.64      0.29        33\n",
      "         114       0.41      0.74      0.53       270\n",
      "         115       0.05      0.33      0.09        51\n",
      "         116       0.26      0.88      0.41        34\n",
      "         117       0.80      1.00      0.89         4\n",
      "         118       0.44      0.33      0.38        91\n",
      "         119       0.01      0.80      0.02         5\n",
      "         120       0.05      0.64      0.10        11\n",
      "         121       0.03      0.43      0.05        28\n",
      "         122       0.14      0.89      0.24         9\n",
      "         123       0.49      0.65      0.56       166\n",
      "         124       0.02      0.22      0.04        18\n",
      "         125       0.02      0.86      0.04         7\n",
      "         126       0.12      0.15      0.14        13\n",
      "         127       0.18      0.64      0.28       239\n",
      "         128       0.30      0.75      0.43       276\n",
      "         129       0.01      0.67      0.02         6\n",
      "         130       0.25      0.74      0.37        35\n",
      "         131       0.17      0.92      0.29        13\n",
      "         132       0.02      1.00      0.03         2\n",
      "         133       0.01      1.00      0.02         5\n",
      "         134       0.02      0.50      0.04         2\n",
      "         135       0.01      1.00      0.01         2\n",
      "         136       0.10      0.48      0.17        75\n",
      "         137       0.01      0.43      0.01         7\n",
      "         138       0.06      0.46      0.10        67\n",
      "         139       0.28      0.51      0.36       318\n",
      "         140       0.01      0.70      0.02        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.17      0.65      0.27      9022\n",
      "   macro avg       0.20      0.60      0.25      9022\n",
      "weighted avg       0.34      0.65      0.43      9022\n",
      " samples avg       0.20      0.75      0.29      9022\n",
      "\n",
      "Time taken to run this cell : 1:37:52.227923\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='hinge', alpha=0.001, penalty='l2', class_weight=\"balanced\", n_jobs = -1))\n",
    "classifier.fit(x_train_4, y_train)\n",
    "predictions = classifier.predict(x_test_4)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_5 = np.hstack((x_train_4, x_train_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_5 = np.hstack((x_test_4, x_test_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('all1.npy_for_every_feature', x_train_5)\n",
    "np.save('all2_for_every_feature.npy', x_test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.0033715441672285905\n",
      "Hamming loss  0.06653813643831974\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1892, Recall: 0.6409, F1-measure: 0.2921\n",
      "Macro-average quality numbers\n",
      "Precision: 0.1661, Recall: 0.5899, F1-measure: 0.2263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.54      0.15        35\n",
      "           1       0.21      0.68      0.31       117\n",
      "           2       0.58      1.00      0.73        26\n",
      "           3       0.01      0.18      0.02        11\n",
      "           4       0.10      0.85      0.18        13\n",
      "           5       0.19      1.00      0.32        26\n",
      "           6       0.08      0.80      0.14        15\n",
      "           7       0.12      0.73      0.20        75\n",
      "           8       0.01      0.25      0.01         4\n",
      "           9       0.30      1.00      0.46        31\n",
      "          10       0.09      0.88      0.16         8\n",
      "          11       0.03      0.20      0.05        20\n",
      "          12       0.11      0.49      0.18        79\n",
      "          13       0.05      0.56      0.09         9\n",
      "          14       0.03      1.00      0.06         3\n",
      "          15       0.05      0.47      0.09        15\n",
      "          16       0.06      0.45      0.11        11\n",
      "          17       0.15      0.37      0.21       120\n",
      "          18       0.22      0.54      0.32        24\n",
      "          19       0.10      0.42      0.17        72\n",
      "          20       0.29      0.71      0.42       351\n",
      "          21       0.11      0.47      0.18        32\n",
      "          22       0.06      0.17      0.08        35\n",
      "          23       0.03      0.17      0.06        29\n",
      "          24       0.10      0.39      0.16        49\n",
      "          25       0.54      0.75      0.63       142\n",
      "          26       0.15      0.51      0.23        65\n",
      "          27       0.04      0.40      0.07        10\n",
      "          28       0.64      0.82      0.72       515\n",
      "          29       0.51      1.00      0.67        90\n",
      "          30       0.14      0.42      0.20        65\n",
      "          31       0.08      1.00      0.15         9\n",
      "          32       0.11      0.52      0.19        21\n",
      "          33       0.25      0.56      0.34        54\n",
      "          34       0.25      0.79      0.38        19\n",
      "          35       0.79      1.00      0.88        26\n",
      "          36       0.16      0.73      0.26        78\n",
      "          37       0.26      0.57      0.35       150\n",
      "          38       0.13      0.62      0.21        82\n",
      "          39       0.02      0.11      0.04        19\n",
      "          40       0.23      0.18      0.20        28\n",
      "          41       0.06      1.00      0.11         5\n",
      "          42       0.43      0.72      0.53        60\n",
      "          43       0.61      0.65      0.63       885\n",
      "          44       0.11      0.47      0.18        66\n",
      "          45       0.52      1.00      0.68       111\n",
      "          46       0.00      1.00      0.00         1\n",
      "          47       0.10      0.61      0.16        38\n",
      "          48       0.08      0.42      0.13        31\n",
      "          49       0.36      0.97      0.53        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.78      0.93      0.85        42\n",
      "          52       0.19      0.68      0.29       229\n",
      "          53       0.06      0.21      0.09        47\n",
      "          54       0.04      0.75      0.08         8\n",
      "          55       0.05      0.33      0.08        24\n",
      "          56       0.39      0.71      0.50       268\n",
      "          57       0.33      0.69      0.45       311\n",
      "          58       0.77      0.82      0.79       142\n",
      "          59       0.29      0.50      0.37       138\n",
      "          60       0.74      0.92      0.82        53\n",
      "          61       0.71      0.71      0.71        49\n",
      "          62       0.37      0.59      0.46        61\n",
      "          63       0.10      0.54      0.16        37\n",
      "          64       0.01      0.50      0.01         6\n",
      "          65       0.21      0.60      0.32       153\n",
      "          66       0.04      0.30      0.07        20\n",
      "          67       0.12      0.69      0.21        52\n",
      "          68       0.57      0.74      0.64       593\n",
      "          69       0.01      0.25      0.02         4\n",
      "          70       0.01      0.17      0.02         6\n",
      "          71       0.06      0.33      0.09        21\n",
      "          72       0.08      0.75      0.14        12\n",
      "          73       0.07      1.00      0.14         2\n",
      "          74       0.03      0.27      0.06        11\n",
      "          75       0.07      0.80      0.13         5\n",
      "          76       0.08      0.89      0.14         9\n",
      "          77       0.21      0.93      0.35        15\n",
      "          78       0.01      0.75      0.03         4\n",
      "          79       0.03      0.50      0.06         4\n",
      "          80       0.10      0.93      0.19        14\n",
      "          81       0.00      0.33      0.01         3\n",
      "          82       0.24      0.35      0.29        20\n",
      "          83       0.09      0.31      0.14        36\n",
      "          84       0.01      0.11      0.02         9\n",
      "          85       0.03      1.00      0.06         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.27      0.64      0.37       248\n",
      "          89       0.07      0.67      0.12         3\n",
      "          90       0.10      0.60      0.16        25\n",
      "          91       0.23      0.42      0.30       200\n",
      "          92       0.02      0.33      0.04         9\n",
      "          93       0.08      0.42      0.14        50\n",
      "          94       0.02      0.23      0.04        13\n",
      "          95       0.04      0.21      0.07        34\n",
      "          96       0.05      0.41      0.09        17\n",
      "          97       0.15      0.58      0.23        48\n",
      "          98       0.01      1.00      0.02         1\n",
      "          99       0.20      0.95      0.33        81\n",
      "         100       0.49      1.00      0.66       100\n",
      "         101       0.06      0.39      0.11        18\n",
      "         102       0.01      1.00      0.02         3\n",
      "         103       0.08      1.00      0.15         5\n",
      "         104       0.09      0.70      0.15        10\n",
      "         105       0.33      1.00      0.50         6\n",
      "         106       0.02      1.00      0.03         3\n",
      "         107       0.08      0.50      0.13        14\n",
      "         108       0.29      0.68      0.41        22\n",
      "         109       0.11      0.11      0.11        54\n",
      "         110       0.05      0.46      0.09        13\n",
      "         111       0.04      0.25      0.08        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.14      0.76      0.24        33\n",
      "         114       0.32      0.80      0.46       270\n",
      "         115       0.12      0.29      0.17        51\n",
      "         116       0.23      0.97      0.37        34\n",
      "         117       0.06      1.00      0.11         4\n",
      "         118       0.16      0.44      0.24        91\n",
      "         119       0.02      0.80      0.04         5\n",
      "         120       0.11      0.64      0.19        11\n",
      "         121       0.21      0.46      0.29        28\n",
      "         122       0.07      0.89      0.14         9\n",
      "         123       0.37      0.70      0.49       166\n",
      "         124       0.03      0.17      0.05        18\n",
      "         125       0.04      0.86      0.07         7\n",
      "         126       0.01      0.15      0.02        13\n",
      "         127       0.22      0.46      0.30       239\n",
      "         128       0.32      0.76      0.45       276\n",
      "         129       0.01      0.67      0.02         6\n",
      "         130       0.40      0.74      0.52        35\n",
      "         131       0.19      0.92      0.32        13\n",
      "         132       0.06      1.00      0.12         2\n",
      "         133       0.03      0.80      0.05         5\n",
      "         134       0.01      0.50      0.01         2\n",
      "         135       0.01      1.00      0.03         2\n",
      "         136       0.11      0.35      0.17        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.46      0.28      0.35        67\n",
      "         139       0.36      0.49      0.41       318\n",
      "         140       0.01      0.30      0.03        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.19      0.64      0.29      9022\n",
      "   macro avg       0.17      0.59      0.23      9022\n",
      "weighted avg       0.34      0.64      0.42      9022\n",
      " samples avg       0.28      0.73      0.37      9022\n",
      "\n",
      "Time taken to run this cell : 1:15:52.485191\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs = -1)\n",
    "classifier.fit(x_train_5, y_train)\n",
    "predictions = classifier.predict(x_test_5)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.015509103169251517\n",
      "Hamming loss  0.04723248459061856\n",
      "Micro-average quality numbers\n",
      "Precision: 0.2283, Recall: 0.5062, F1-measure: 0.3147\n",
      "Macro-average quality numbers\n",
      "Precision: 0.2706, Recall: 0.5091, F1-measure: 0.2911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.06      0.07        35\n",
      "           1       0.38      0.44      0.41       117\n",
      "           2       0.57      1.00      0.72        26\n",
      "           3       0.01      0.18      0.02        11\n",
      "           4       0.15      0.69      0.24        13\n",
      "           5       0.35      0.92      0.51        26\n",
      "           6       0.09      0.60      0.15        15\n",
      "           7       0.30      0.31      0.30        75\n",
      "           8       0.04      0.25      0.06         4\n",
      "           9       0.43      0.90      0.58        31\n",
      "          10       0.10      0.88      0.18         8\n",
      "          11       0.06      0.05      0.06        20\n",
      "          12       0.38      0.25      0.30        79\n",
      "          13       0.02      0.78      0.03         9\n",
      "          14       0.02      1.00      0.04         3\n",
      "          15       0.03      0.47      0.06        15\n",
      "          16       0.01      0.27      0.03        11\n",
      "          17       0.21      0.19      0.20       120\n",
      "          18       0.48      0.50      0.49        24\n",
      "          19       0.19      0.25      0.22        72\n",
      "          20       0.43      0.47      0.45       351\n",
      "          21       0.10      0.56      0.18        32\n",
      "          22       0.10      0.09      0.09        35\n",
      "          23       0.06      0.24      0.10        29\n",
      "          24       0.21      0.12      0.15        49\n",
      "          25       0.69      0.59      0.64       142\n",
      "          26       0.26      0.23      0.25        65\n",
      "          27       0.14      0.20      0.17        10\n",
      "          28       0.57      0.85      0.68       515\n",
      "          29       0.64      0.97      0.77        90\n",
      "          30       0.29      0.32      0.31        65\n",
      "          31       0.11      0.89      0.19         9\n",
      "          32       0.50      0.38      0.43        21\n",
      "          33       0.61      0.41      0.49        54\n",
      "          34       0.34      0.68      0.46        19\n",
      "          35       0.84      0.81      0.82        26\n",
      "          36       0.50      0.44      0.47        78\n",
      "          37       0.38      0.37      0.37       150\n",
      "          38       0.21      0.22      0.22        82\n",
      "          39       0.04      0.42      0.07        19\n",
      "          40       0.04      0.18      0.07        28\n",
      "          41       0.07      0.80      0.13         5\n",
      "          42       0.63      0.63      0.63        60\n",
      "          43       0.61      0.63      0.62       885\n",
      "          44       0.27      0.26      0.26        66\n",
      "          45       0.67      0.90      0.77       111\n",
      "          46       0.00      1.00      0.01         1\n",
      "          47       0.19      0.39      0.26        38\n",
      "          48       0.26      0.29      0.27        31\n",
      "          49       0.43      0.79      0.55        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.83      0.90      0.86        42\n",
      "          52       0.30      0.30      0.30       229\n",
      "          53       0.25      0.15      0.19        47\n",
      "          54       0.29      0.88      0.44         8\n",
      "          55       0.09      0.25      0.14        24\n",
      "          56       0.52      0.56      0.54       268\n",
      "          57       0.30      0.30      0.30       311\n",
      "          58       0.81      0.77      0.79       142\n",
      "          59       0.44      0.38      0.41       138\n",
      "          60       0.75      0.92      0.83        53\n",
      "          61       0.81      0.71      0.76        49\n",
      "          62       0.73      0.54      0.62        61\n",
      "          63       0.24      0.32      0.27        37\n",
      "          64       0.01      0.50      0.02         6\n",
      "          65       0.45      0.39      0.41       153\n",
      "          66       0.04      0.15      0.06        20\n",
      "          67       0.23      0.31      0.26        52\n",
      "          68       0.56      0.70      0.62       593\n",
      "          69       0.00      0.25      0.01         4\n",
      "          70       0.01      0.17      0.01         6\n",
      "          71       0.50      0.19      0.28        21\n",
      "          72       0.41      0.75      0.53        12\n",
      "          73       0.07      1.00      0.13         2\n",
      "          74       0.04      0.27      0.06        11\n",
      "          75       0.03      1.00      0.06         5\n",
      "          76       0.26      1.00      0.42         9\n",
      "          77       0.39      0.87      0.54        15\n",
      "          78       0.04      0.75      0.08         4\n",
      "          79       0.67      0.50      0.57         4\n",
      "          80       0.12      0.93      0.21        14\n",
      "          81       0.00      0.33      0.01         3\n",
      "          82       0.02      0.65      0.03        20\n",
      "          83       0.22      0.11      0.15        36\n",
      "          84       1.00      0.11      0.20         9\n",
      "          85       0.86      1.00      0.92         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.28      0.45      0.35       248\n",
      "          89       0.13      0.67      0.22         3\n",
      "          90       0.15      0.24      0.18        25\n",
      "          91       0.43      0.25      0.32       200\n",
      "          92       0.03      0.56      0.06         9\n",
      "          93       0.18      0.12      0.14        50\n",
      "          94       0.43      0.23      0.30        13\n",
      "          95       0.25      0.06      0.10        34\n",
      "          96       0.08      0.41      0.13        17\n",
      "          97       0.46      0.50      0.48        48\n",
      "          98       0.00      1.00      0.01         1\n",
      "          99       0.06      0.01      0.02        81\n",
      "         100       0.69      0.94      0.79       100\n",
      "         101       0.08      0.22      0.12        18\n",
      "         102       0.27      1.00      0.43         3\n",
      "         103       0.19      1.00      0.32         5\n",
      "         104       0.12      0.70      0.21        10\n",
      "         105       0.12      1.00      0.21         6\n",
      "         106       0.04      1.00      0.07         3\n",
      "         107       0.14      0.57      0.22        14\n",
      "         108       0.13      0.73      0.22        22\n",
      "         109       0.21      0.11      0.15        54\n",
      "         110       0.03      0.54      0.06        13\n",
      "         111       0.12      0.33      0.18        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.30      0.42      0.35        33\n",
      "         114       0.43      0.65      0.52       270\n",
      "         115       0.20      0.25      0.22        51\n",
      "         116       0.26      0.59      0.36        34\n",
      "         117       0.80      1.00      0.89         4\n",
      "         118       0.66      0.30      0.41        91\n",
      "         119       0.06      0.80      0.11         5\n",
      "         120       0.27      1.00      0.42        11\n",
      "         121       0.35      0.32      0.33        28\n",
      "         122       0.20      0.89      0.33         9\n",
      "         123       0.64      0.62      0.63       166\n",
      "         124       0.14      0.11      0.12        18\n",
      "         125       0.07      0.86      0.13         7\n",
      "         126       0.04      0.15      0.06        13\n",
      "         127       0.33      0.30      0.32       239\n",
      "         128       0.43      0.62      0.51       276\n",
      "         129       0.01      0.67      0.01         6\n",
      "         130       0.44      0.74      0.55        35\n",
      "         131       0.33      0.92      0.49        13\n",
      "         132       0.05      1.00      0.09         2\n",
      "         133       0.11      0.80      0.20         5\n",
      "         134       0.08      0.50      0.14         2\n",
      "         135       0.11      1.00      0.20         2\n",
      "         136       0.06      0.05      0.06        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.49      0.31      0.38        67\n",
      "         139       0.29      0.44      0.35       318\n",
      "         140       0.21      0.30      0.25        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.23      0.51      0.31      9022\n",
      "   macro avg       0.27      0.51      0.29      9022\n",
      "weighted avg       0.43      0.51      0.45      9022\n",
      " samples avg       0.27      0.61      0.35      9022\n",
      "\n",
      "Time taken to run this cell : 0:52:35.231668\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.0001, penalty='l2', class_weight=\"balanced\"), n_jobs = -1)\n",
    "classifier.fit(x_train_5, y_train)\n",
    "predictions = classifier.predict(x_test_5)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.07720836142953473\n",
      "Hamming loss  0.04128004710664527\n",
      "Micro-average quality numbers\n",
      "Precision: 0.2440, Recall: 0.4419, F1-measure: 0.3144\n",
      "Macro-average quality numbers\n",
      "Precision: 0.2542, Recall: 0.5118, F1-measure: 0.2801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.26      0.14        35\n",
      "           1       0.49      0.25      0.33       117\n",
      "           2       0.72      1.00      0.84        26\n",
      "           3       0.02      0.27      0.03        11\n",
      "           4       0.19      0.77      0.30        13\n",
      "           5       0.25      1.00      0.40        26\n",
      "           6       0.15      0.93      0.25        15\n",
      "           7       0.28      0.32      0.30        75\n",
      "           8       0.05      0.50      0.08         4\n",
      "           9       0.51      0.97      0.67        31\n",
      "          10       0.54      0.88      0.67         8\n",
      "          11       0.02      0.70      0.04        20\n",
      "          12       0.26      0.29      0.27        79\n",
      "          13       0.03      0.22      0.06         9\n",
      "          14       0.03      1.00      0.06         3\n",
      "          15       0.19      0.33      0.24        15\n",
      "          16       0.03      0.55      0.05        11\n",
      "          17       0.14      0.03      0.05       120\n",
      "          18       0.46      0.50      0.48        24\n",
      "          19       0.05      0.43      0.09        72\n",
      "          20       0.47      0.28      0.35       351\n",
      "          21       0.14      0.47      0.22        32\n",
      "          22       0.10      0.20      0.13        35\n",
      "          23       0.17      0.14      0.15        29\n",
      "          24       0.23      0.10      0.14        49\n",
      "          25       0.80      0.49      0.61       142\n",
      "          26       0.21      0.37      0.27        65\n",
      "          27       0.04      0.30      0.06        10\n",
      "          28       0.68      0.71      0.69       515\n",
      "          29       0.71      0.88      0.79        90\n",
      "          30       0.19      0.29      0.23        65\n",
      "          31       0.31      0.89      0.46         9\n",
      "          32       0.04      0.57      0.07        21\n",
      "          33       0.33      0.54      0.41        54\n",
      "          34       0.23      0.74      0.35        19\n",
      "          35       0.90      1.00      0.95        26\n",
      "          36       0.38      0.38      0.38        78\n",
      "          37       0.47      0.25      0.33       150\n",
      "          38       0.13      0.41      0.20        82\n",
      "          39       0.09      0.32      0.14        19\n",
      "          40       0.08      0.14      0.10        28\n",
      "          41       0.09      1.00      0.17         5\n",
      "          42       0.58      0.47      0.52        60\n",
      "          43       0.57      0.61      0.59       885\n",
      "          44       0.14      0.27      0.19        66\n",
      "          45       0.66      0.77      0.71       111\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.17      0.32      0.22        38\n",
      "          48       0.15      0.35      0.22        31\n",
      "          49       0.44      0.85      0.58        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.83      0.93      0.88        42\n",
      "          52       0.42      0.16      0.23       229\n",
      "          53       0.10      0.09      0.09        47\n",
      "          54       0.41      0.88      0.56         8\n",
      "          55       0.07      0.12      0.09        24\n",
      "          56       0.57      0.29      0.39       268\n",
      "          57       0.43      0.23      0.30       311\n",
      "          58       0.88      0.75      0.81       142\n",
      "          59       0.34      0.39      0.36       138\n",
      "          60       0.79      0.92      0.85        53\n",
      "          61       0.78      0.73      0.76        49\n",
      "          62       0.44      0.56      0.49        61\n",
      "          63       0.15      0.46      0.22        37\n",
      "          64       0.01      0.50      0.02         6\n",
      "          65       0.51      0.25      0.33       153\n",
      "          66       0.02      0.50      0.04        20\n",
      "          67       0.21      0.29      0.25        52\n",
      "          68       0.60      0.55      0.58       593\n",
      "          69       0.01      0.50      0.02         4\n",
      "          70       0.01      0.17      0.01         6\n",
      "          71       0.08      0.19      0.11        21\n",
      "          72       0.26      0.83      0.40        12\n",
      "          73       0.07      1.00      0.13         2\n",
      "          74       0.03      0.45      0.06        11\n",
      "          75       0.33      1.00      0.50         5\n",
      "          76       0.27      1.00      0.43         9\n",
      "          77       0.44      0.93      0.60        15\n",
      "          78       0.01      0.75      0.02         4\n",
      "          79       0.67      0.50      0.57         4\n",
      "          80       0.17      0.86      0.29        14\n",
      "          81       0.06      0.33      0.10         3\n",
      "          82       0.06      0.45      0.10        20\n",
      "          83       0.10      0.19      0.13        36\n",
      "          84       0.05      0.11      0.06         9\n",
      "          85       0.75      1.00      0.86         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.37      0.20      0.26       248\n",
      "          89       0.13      0.67      0.22         3\n",
      "          90       0.12      0.12      0.12        25\n",
      "          91       0.39      0.23      0.29       200\n",
      "          92       0.04      0.67      0.08         9\n",
      "          93       0.21      0.06      0.09        50\n",
      "          94       0.09      0.62      0.15        13\n",
      "          95       0.08      0.12      0.10        34\n",
      "          96       0.03      0.47      0.05        17\n",
      "          97       0.53      0.50      0.52        48\n",
      "          98       0.01      1.00      0.02         1\n",
      "          99       0.08      0.01      0.02        81\n",
      "         100       0.72      0.83      0.77       100\n",
      "         101       0.15      0.28      0.20        18\n",
      "         102       0.27      1.00      0.43         3\n",
      "         103       0.33      1.00      0.50         5\n",
      "         104       0.05      0.80      0.10        10\n",
      "         105       0.06      1.00      0.12         6\n",
      "         106       0.10      1.00      0.19         3\n",
      "         107       0.23      0.50      0.32        14\n",
      "         108       0.21      0.68      0.32        22\n",
      "         109       0.29      0.04      0.07        54\n",
      "         110       0.07      0.62      0.13        13\n",
      "         111       0.04      0.33      0.08        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.08      0.97      0.14        33\n",
      "         114       0.45      0.32      0.38       270\n",
      "         115       0.16      0.12      0.13        51\n",
      "         116       0.22      0.88      0.35        34\n",
      "         117       0.67      1.00      0.80         4\n",
      "         118       0.72      0.29      0.41        91\n",
      "         119       0.12      0.80      0.22         5\n",
      "         120       0.11      1.00      0.19        11\n",
      "         121       0.41      0.32      0.36        28\n",
      "         122       0.18      0.89      0.30         9\n",
      "         123       0.34      0.66      0.45       166\n",
      "         124       0.10      0.17      0.12        18\n",
      "         125       0.13      0.86      0.23         7\n",
      "         126       0.03      0.31      0.06        13\n",
      "         127       0.34      0.23      0.28       239\n",
      "         128       0.45      0.61      0.52       276\n",
      "         129       0.05      0.67      0.09         6\n",
      "         130       0.38      0.49      0.42        35\n",
      "         131       0.33      0.92      0.49        13\n",
      "         132       0.06      1.00      0.12         2\n",
      "         133       0.08      0.80      0.14         5\n",
      "         134       0.05      0.50      0.09         2\n",
      "         135       0.10      1.00      0.17         2\n",
      "         136       0.10      0.08      0.09        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.36      0.28      0.32        67\n",
      "         139       0.35      0.39      0.37       318\n",
      "         140       0.17      0.20      0.18        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.24      0.44      0.31      9022\n",
      "   macro avg       0.25      0.51      0.28      9022\n",
      "weighted avg       0.43      0.44      0.41      9022\n",
      " samples avg       0.32      0.54      0.35      9022\n",
      "\n",
      "Time taken to run this cell : 0:16:36.482839\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.00001, penalty='l2', class_weight=\"balanced\"), n_jobs = -1)\n",
    "classifier.fit(x_train_5, y_train)\n",
    "predictions = classifier.predict(x_test_5)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.0\n",
      "Hamming loss  0.07879441178425917\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1578, Recall: 0.6173, F1-measure: 0.2513\n",
      "Macro-average quality numbers\n",
      "Precision: 0.1867, Recall: 0.5947, F1-measure: 0.2395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.20      0.16        35\n",
      "           1       0.25      0.54      0.34       117\n",
      "           2       0.67      1.00      0.80        26\n",
      "           3       0.01      0.18      0.01        11\n",
      "           4       0.15      0.69      0.25        13\n",
      "           5       0.23      0.96      0.38        26\n",
      "           6       0.06      0.67      0.11        15\n",
      "           7       0.16      0.51      0.24        75\n",
      "           8       0.00      0.50      0.01         4\n",
      "           9       0.27      1.00      0.42        31\n",
      "          10       0.70      0.88      0.78         8\n",
      "          11       0.04      0.65      0.07        20\n",
      "          12       0.16      0.35      0.22        79\n",
      "          13       0.02      0.56      0.04         9\n",
      "          14       0.01      1.00      0.03         3\n",
      "          15       0.02      0.67      0.04        15\n",
      "          16       0.02      0.45      0.04        11\n",
      "          17       0.19      0.22      0.20       120\n",
      "          18       0.21      0.54      0.30        24\n",
      "          19       0.12      0.32      0.18        72\n",
      "          20       0.33      0.65      0.44       351\n",
      "          21       0.17      0.53      0.25        32\n",
      "          22       0.04      0.14      0.06        35\n",
      "          23       0.04      0.17      0.07        29\n",
      "          24       0.06      0.57      0.11        49\n",
      "          25       0.69      0.65      0.67       142\n",
      "          26       0.21      0.46      0.29        65\n",
      "          27       0.01      0.40      0.01        10\n",
      "          28       0.61      0.84      0.71       515\n",
      "          29       0.63      0.97      0.76        90\n",
      "          30       0.14      0.37      0.20        65\n",
      "          31       0.05      1.00      0.10         9\n",
      "          32       0.16      0.48      0.24        21\n",
      "          33       0.53      0.52      0.52        54\n",
      "          34       0.25      0.95      0.40        19\n",
      "          35       0.49      1.00      0.66        26\n",
      "          36       0.20      0.64      0.30        78\n",
      "          37       0.26      0.47      0.34       150\n",
      "          38       0.12      0.48      0.19        82\n",
      "          39       0.03      0.32      0.05        19\n",
      "          40       0.19      0.18      0.19        28\n",
      "          41       0.03      1.00      0.05         5\n",
      "          42       0.21      0.70      0.33        60\n",
      "          43       0.58      0.76      0.66       885\n",
      "          44       0.09      0.50      0.15        66\n",
      "          45       0.67      0.92      0.78       111\n",
      "          46       0.01      1.00      0.01         1\n",
      "          47       0.10      0.53      0.16        38\n",
      "          48       0.07      0.35      0.11        31\n",
      "          49       0.31      0.97      0.47        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.30      0.88      0.44        42\n",
      "          52       0.21      0.48      0.29       229\n",
      "          53       0.05      0.17      0.08        47\n",
      "          54       0.03      0.75      0.07         8\n",
      "          55       0.08      0.29      0.13        24\n",
      "          56       0.37      0.67      0.48       268\n",
      "          57       0.36      0.64      0.46       311\n",
      "          58       0.69      0.80      0.74       142\n",
      "          59       0.37      0.41      0.39       138\n",
      "          60       0.75      0.92      0.83        53\n",
      "          61       0.59      0.73      0.65        49\n",
      "          62       0.58      0.54      0.56        61\n",
      "          63       0.09      0.57      0.16        37\n",
      "          64       0.02      0.50      0.04         6\n",
      "          65       0.31      0.47      0.38       153\n",
      "          66       0.08      0.45      0.14        20\n",
      "          67       0.11      0.67      0.19        52\n",
      "          68       0.48      0.84      0.61       593\n",
      "          69       0.01      0.75      0.01         4\n",
      "          70       0.00      0.17      0.01         6\n",
      "          71       0.02      0.43      0.04        21\n",
      "          72       0.03      0.83      0.06        12\n",
      "          73       0.01      1.00      0.01         2\n",
      "          74       0.10      0.27      0.15        11\n",
      "          75       0.25      1.00      0.40         5\n",
      "          76       0.04      1.00      0.08         9\n",
      "          77       0.25      0.93      0.40        15\n",
      "          78       0.00      1.00      0.01         4\n",
      "          79       0.67      0.50      0.57         4\n",
      "          80       0.10      1.00      0.18        14\n",
      "          81       0.00      0.33      0.00         3\n",
      "          82       0.08      0.25      0.12        20\n",
      "          83       0.07      0.47      0.12        36\n",
      "          84       0.07      0.11      0.09         9\n",
      "          85       0.60      1.00      0.75         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.30      0.50      0.38       248\n",
      "          89       0.13      0.67      0.22         3\n",
      "          90       0.07      0.60      0.12        25\n",
      "          91       0.19      0.34      0.25       200\n",
      "          92       0.03      0.67      0.05         9\n",
      "          93       0.09      0.30      0.13        50\n",
      "          94       0.01      0.23      0.03        13\n",
      "          95       0.05      0.21      0.08        34\n",
      "          96       0.04      0.41      0.07        17\n",
      "          97       0.27      0.50      0.35        48\n",
      "          98       0.01      1.00      0.01         1\n",
      "          99       0.23      0.77      0.35        81\n",
      "         100       0.55      0.95      0.70       100\n",
      "         101       0.05      0.50      0.10        18\n",
      "         102       0.01      1.00      0.03         3\n",
      "         103       0.09      1.00      0.16         5\n",
      "         104       0.02      0.80      0.03        10\n",
      "         105       0.05      1.00      0.10         6\n",
      "         106       0.03      1.00      0.06         3\n",
      "         107       0.07      0.50      0.12        14\n",
      "         108       0.06      0.77      0.10        22\n",
      "         109       0.14      0.11      0.12        54\n",
      "         110       0.03      0.62      0.05        13\n",
      "         111       0.02      0.25      0.03        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.07      0.97      0.13        33\n",
      "         114       0.38      0.76      0.51       270\n",
      "         115       0.14      0.16      0.15        51\n",
      "         116       0.25      0.94      0.39        34\n",
      "         117       0.11      1.00      0.20         4\n",
      "         118       0.35      0.35      0.35        91\n",
      "         119       0.01      0.80      0.02         5\n",
      "         120       0.10      1.00      0.18        11\n",
      "         121       0.47      0.29      0.36        28\n",
      "         122       0.11      0.89      0.20         9\n",
      "         123       0.62      0.63      0.62       166\n",
      "         124       0.02      0.22      0.04        18\n",
      "         125       0.02      0.86      0.03         7\n",
      "         126       0.05      0.31      0.09        13\n",
      "         127       0.28      0.37      0.32       239\n",
      "         128       0.39      0.68      0.49       276\n",
      "         129       0.01      0.67      0.03         6\n",
      "         130       0.31      0.74      0.44        35\n",
      "         131       0.33      0.92      0.49        13\n",
      "         132       0.05      1.00      0.10         2\n",
      "         133       0.09      0.80      0.16         5\n",
      "         134       0.01      0.50      0.02         2\n",
      "         135       0.50      1.00      0.67         2\n",
      "         136       0.09      0.08      0.08        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.43      0.30      0.35        67\n",
      "         139       0.29      0.57      0.38       318\n",
      "         140       0.01      0.30      0.03        10\n",
      "         141       0.01      0.43      0.01         7\n",
      "\n",
      "   micro avg       0.16      0.62      0.25      9022\n",
      "   macro avg       0.19      0.59      0.24      9022\n",
      "weighted avg       0.35      0.62      0.43      9022\n",
      " samples avg       0.22      0.71      0.31      9022\n",
      "\n",
      "Time taken to run this cell : 0:53:28.273467\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='hinge', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs = -1)\n",
    "classifier.fit(x_train_5, y_train)\n",
    "predictions = classifier.predict(x_test_5)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.009777478084962913\n",
      "Hamming loss  0.05204287084611513\n",
      "Micro-average quality numbers\n",
      "Precision: 0.2053, Recall: 0.4980, F1-measure: 0.2908\n",
      "Macro-average quality numbers\n",
      "Precision: 0.2024, Recall: 0.5379, F1-measure: 0.2478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.17      0.13        35\n",
      "           1       0.20      0.56      0.30       117\n",
      "           2       0.67      1.00      0.80        26\n",
      "           3       0.02      0.27      0.04        11\n",
      "           4       0.12      0.92      0.21        13\n",
      "           5       0.31      1.00      0.47        26\n",
      "           6       0.11      0.93      0.19        15\n",
      "           7       0.19      0.48      0.28        75\n",
      "           8       0.00      0.25      0.01         4\n",
      "           9       0.29      1.00      0.45        31\n",
      "          10       0.07      0.88      0.13         8\n",
      "          11       0.02      0.10      0.04        20\n",
      "          12       0.26      0.20      0.23        79\n",
      "          13       0.03      0.56      0.05         9\n",
      "          14       0.02      1.00      0.04         3\n",
      "          15       0.04      0.53      0.07        15\n",
      "          16       0.05      0.55      0.09        11\n",
      "          17       0.23      0.16      0.19       120\n",
      "          18       0.07      0.58      0.13        24\n",
      "          19       0.17      0.35      0.23        72\n",
      "          20       0.45      0.36      0.40       351\n",
      "          21       0.13      0.34      0.19        32\n",
      "          22       0.03      0.14      0.06        35\n",
      "          23       0.08      0.14      0.10        29\n",
      "          24       0.20      0.16      0.18        49\n",
      "          25       0.41      0.70      0.52       142\n",
      "          26       0.17      0.43      0.24        65\n",
      "          27       0.02      0.40      0.04        10\n",
      "          28       0.70      0.70      0.70       515\n",
      "          29       0.63      0.90      0.74        90\n",
      "          30       0.13      0.49      0.20        65\n",
      "          31       0.26      0.89      0.40         9\n",
      "          32       0.11      0.52      0.19        21\n",
      "          33       0.17      0.67      0.27        54\n",
      "          34       0.22      0.79      0.34        19\n",
      "          35       0.90      1.00      0.95        26\n",
      "          36       0.34      0.46      0.39        78\n",
      "          37       0.42      0.32      0.36       150\n",
      "          38       0.09      0.52      0.16        82\n",
      "          39       0.05      0.05      0.05        19\n",
      "          40       0.03      0.18      0.05        28\n",
      "          41       0.05      1.00      0.10         5\n",
      "          42       0.34      0.65      0.44        60\n",
      "          43       0.55      0.68      0.61       885\n",
      "          44       0.17      0.32      0.22        66\n",
      "          45       0.64      0.93      0.76       111\n",
      "          46       0.00      1.00      0.00         1\n",
      "          47       0.17      0.32      0.22        38\n",
      "          48       0.16      0.29      0.20        31\n",
      "          49       0.42      0.76      0.54        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.83      0.93      0.88        42\n",
      "          52       0.26      0.33      0.29       229\n",
      "          53       0.12      0.13      0.13        47\n",
      "          54       0.15      1.00      0.25         8\n",
      "          55       0.03      0.50      0.06        24\n",
      "          56       0.49      0.50      0.50       268\n",
      "          57       0.37      0.30      0.33       311\n",
      "          58       0.79      0.80      0.80       142\n",
      "          59       0.53      0.28      0.37       138\n",
      "          60       0.67      0.92      0.78        53\n",
      "          61       0.51      0.71      0.59        49\n",
      "          62       0.52      0.44      0.48        61\n",
      "          63       0.09      0.57      0.16        37\n",
      "          64       0.01      0.50      0.03         6\n",
      "          65       0.26      0.44      0.33       153\n",
      "          66       0.05      0.15      0.07        20\n",
      "          67       0.19      0.40      0.26        52\n",
      "          68       0.53      0.70      0.61       593\n",
      "          69       0.01      0.75      0.01         4\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.03      0.62      0.06        21\n",
      "          72       0.13      0.83      0.23        12\n",
      "          73       0.04      1.00      0.08         2\n",
      "          74       0.05      0.27      0.09        11\n",
      "          75       0.07      1.00      0.12         5\n",
      "          76       0.16      1.00      0.28         9\n",
      "          77       0.16      0.93      0.27        15\n",
      "          78       0.01      0.75      0.03         4\n",
      "          79       0.07      0.50      0.12         4\n",
      "          80       0.10      0.93      0.19        14\n",
      "          81       0.00      0.33      0.01         3\n",
      "          82       0.05      0.45      0.10        20\n",
      "          83       0.29      0.19      0.23        36\n",
      "          84       0.05      0.11      0.07         9\n",
      "          85       0.60      1.00      0.75         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.27      0.29      0.28       248\n",
      "          89       0.13      0.67      0.22         3\n",
      "          90       0.12      0.64      0.21        25\n",
      "          91       0.46      0.23      0.31       200\n",
      "          92       0.04      0.56      0.07         9\n",
      "          93       0.03      0.10      0.04        50\n",
      "          94       0.11      0.23      0.15        13\n",
      "          95       0.04      0.09      0.06        34\n",
      "          96       0.05      0.41      0.09        17\n",
      "          97       0.49      0.50      0.49        48\n",
      "          98       0.01      1.00      0.01         1\n",
      "          99       0.17      0.01      0.02        81\n",
      "         100       0.69      0.93      0.79       100\n",
      "         101       0.04      0.50      0.08        18\n",
      "         102       0.27      1.00      0.43         3\n",
      "         103       0.16      1.00      0.27         5\n",
      "         104       0.12      0.70      0.21        10\n",
      "         105       0.33      1.00      0.50         6\n",
      "         106       0.06      1.00      0.11         3\n",
      "         107       0.20      0.50      0.29        14\n",
      "         108       0.41      0.68      0.51        22\n",
      "         109       0.04      0.37      0.07        54\n",
      "         110       0.05      0.46      0.09        13\n",
      "         111       0.03      0.33      0.05        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.33      0.61      0.43        33\n",
      "         114       0.34      0.35      0.34       270\n",
      "         115       0.12      0.14      0.13        51\n",
      "         116       0.21      0.91      0.35        34\n",
      "         117       0.31      1.00      0.47         4\n",
      "         118       0.38      0.35      0.37        91\n",
      "         119       0.04      0.80      0.08         5\n",
      "         120       0.09      1.00      0.16        11\n",
      "         121       0.10      0.46      0.17        28\n",
      "         122       0.18      0.89      0.30         9\n",
      "         123       0.30      0.67      0.42       166\n",
      "         124       0.04      0.17      0.07        18\n",
      "         125       0.06      0.86      0.11         7\n",
      "         126       0.04      0.15      0.07        13\n",
      "         127       0.34      0.26      0.29       239\n",
      "         128       0.50      0.46      0.48       276\n",
      "         129       0.00      0.00      0.00         6\n",
      "         130       0.41      0.74      0.53        35\n",
      "         131       0.33      0.92      0.49        13\n",
      "         132       0.05      1.00      0.10         2\n",
      "         133       0.13      0.80      0.22         5\n",
      "         134       0.01      0.50      0.02         2\n",
      "         135       0.06      1.00      0.11         2\n",
      "         136       0.10      0.23      0.14        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.29      0.33      0.31        67\n",
      "         139       0.26      0.34      0.29       318\n",
      "         140       0.15      0.20      0.17        10\n",
      "         141       0.00      0.14      0.01         7\n",
      "\n",
      "   micro avg       0.21      0.50      0.29      9022\n",
      "   macro avg       0.20      0.54      0.25      9022\n",
      "weighted avg       0.38      0.50      0.41      9022\n",
      " samples avg       0.25      0.56      0.31      9022\n",
      "\n",
      "Time taken to run this cell : 0:22:10.266167\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='hinge', alpha=0.0001, penalty='l2', class_weight=\"balanced\"), n_jobs = -1)\n",
    "classifier.fit(x_train_5, y_train)\n",
    "predictions = classifier.predict(x_test_5)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:00:35.064447\n"
     ]
    }
   ],
   "source": [
    "vectorizer_char = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='char', ngram_range=(1, 1),  max_features=20000)\n",
    "x_train_char = vectorizer_char.fit_transform(train['cleaned'])\n",
    "x_test_char = vectorizer_char.transform(test['cleaned'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.0\n",
      "Hamming loss  0.38525827927782474\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0282, Recall: 0.5076, F1-measure: 0.0534\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0259, Recall: 0.4466, F1-measure: 0.0402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.43      0.03        35\n",
      "           1       0.07      0.73      0.13       117\n",
      "           2       0.01      0.92      0.02        26\n",
      "           3       0.00      0.64      0.01        11\n",
      "           4       0.01      0.38      0.03        13\n",
      "           5       0.01      0.65      0.03        26\n",
      "           6       0.01      0.33      0.02        15\n",
      "           7       0.03      0.72      0.06        75\n",
      "           8       0.00      0.25      0.00         4\n",
      "           9       0.00      0.00      0.00        31\n",
      "          10       0.00      0.00      0.00         8\n",
      "          11       0.01      0.55      0.02        20\n",
      "          12       0.03      0.68      0.07        79\n",
      "          13       0.00      0.00      0.00         9\n",
      "          14       0.00      1.00      0.00         3\n",
      "          15       0.00      0.00      0.00        15\n",
      "          16       0.01      0.82      0.01        11\n",
      "          17       0.04      0.98      0.08       120\n",
      "          18       0.01      0.04      0.01        24\n",
      "          19       0.02      0.06      0.03        72\n",
      "          20       0.18      0.34      0.24       351\n",
      "          21       0.01      0.97      0.02        32\n",
      "          22       0.00      0.00      0.00        35\n",
      "          23       0.01      1.00      0.02        29\n",
      "          24       0.02      0.78      0.04        49\n",
      "          25       0.07      0.72      0.12       142\n",
      "          26       0.02      0.95      0.05        65\n",
      "          27       0.00      0.50      0.01        10\n",
      "          28       0.21      0.53      0.30       515\n",
      "          29       0.06      0.59      0.11        90\n",
      "          30       0.04      0.14      0.06        65\n",
      "          31       0.00      0.89      0.01         9\n",
      "          32       0.00      0.00      0.00        21\n",
      "          33       0.02      0.37      0.05        54\n",
      "          34       0.00      0.00      0.00        19\n",
      "          35       0.00      0.00      0.00        26\n",
      "          36       0.06      0.01      0.02        78\n",
      "          37       0.06      0.85      0.11       150\n",
      "          38       0.04      0.46      0.07        82\n",
      "          39       0.00      0.00      0.00        19\n",
      "          40       0.01      0.25      0.02        28\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.02      0.98      0.04        60\n",
      "          43       0.31      0.87      0.46       885\n",
      "          44       0.03      0.80      0.07        66\n",
      "          45       0.04      0.94      0.08       111\n",
      "          46       0.00      1.00      0.00         1\n",
      "          47       0.01      0.16      0.03        38\n",
      "          48       0.02      0.26      0.04        31\n",
      "          49       0.02      0.27      0.04        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.02      0.52      0.04        42\n",
      "          52       0.11      0.23      0.15       229\n",
      "          53       0.00      0.00      0.00        47\n",
      "          54       0.00      0.00      0.00         8\n",
      "          55       0.02      0.54      0.03        24\n",
      "          56       0.12      0.56      0.20       268\n",
      "          57       0.18      0.11      0.14       311\n",
      "          58       0.07      0.20      0.10       142\n",
      "          59       0.06      0.54      0.10       138\n",
      "          60       0.02      0.55      0.04        53\n",
      "          61       0.02      0.67      0.04        49\n",
      "          62       0.00      0.00      0.00        61\n",
      "          63       0.02      0.05      0.03        37\n",
      "          64       0.00      0.33      0.01         6\n",
      "          65       0.07      0.80      0.12       153\n",
      "          66       0.02      0.65      0.03        20\n",
      "          67       0.03      0.67      0.05        52\n",
      "          68       0.24      0.61      0.34       593\n",
      "          69       0.00      0.00      0.00         4\n",
      "          70       0.00      0.83      0.00         6\n",
      "          71       0.02      0.10      0.03        21\n",
      "          72       0.01      0.33      0.01        12\n",
      "          73       0.00      1.00      0.00         2\n",
      "          74       0.00      0.00      0.00        11\n",
      "          75       0.00      0.20      0.01         5\n",
      "          76       0.00      1.00      0.01         9\n",
      "          77       0.01      0.80      0.01        15\n",
      "          78       0.00      1.00      0.00         4\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.01      0.57      0.01        14\n",
      "          81       0.00      0.67      0.00         3\n",
      "          82       0.00      0.00      0.00        20\n",
      "          83       0.02      0.33      0.04        36\n",
      "          84       0.00      1.00      0.01         9\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      1.00      0.00         2\n",
      "          88       0.10      0.53      0.17       248\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.01      1.00      0.02        25\n",
      "          91       0.07      0.52      0.12       200\n",
      "          92       0.00      0.89      0.01         9\n",
      "          93       0.02      1.00      0.04        50\n",
      "          94       0.00      0.00      0.00        13\n",
      "          95       0.02      0.65      0.03        34\n",
      "          96       0.01      0.35      0.01        17\n",
      "          97       0.03      0.29      0.05        48\n",
      "          98       0.00      1.00      0.00         1\n",
      "          99       0.03      0.44      0.06        81\n",
      "         100       0.00      0.00      0.00       100\n",
      "         101       0.01      0.33      0.01        18\n",
      "         102       0.00      1.00      0.00         3\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.00      1.00      0.01        10\n",
      "         105       0.00      0.50      0.00         6\n",
      "         106       0.00      1.00      0.00         3\n",
      "         107       0.02      0.07      0.04        14\n",
      "         108       0.01      0.73      0.01        22\n",
      "         109       0.04      0.09      0.05        54\n",
      "         110       0.01      0.08      0.01        13\n",
      "         111       0.00      1.00      0.01        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00        33\n",
      "         114       0.08      0.01      0.01       270\n",
      "         115       0.03      0.59      0.05        51\n",
      "         116       0.00      0.00      0.00        34\n",
      "         117       0.00      0.00      0.00         4\n",
      "         118       0.03      0.70      0.06        91\n",
      "         119       0.00      0.00      0.00         5\n",
      "         120       0.00      1.00      0.01        11\n",
      "         121       0.02      0.57      0.03        28\n",
      "         122       0.00      1.00      0.01         9\n",
      "         123       0.12      0.38      0.18       166\n",
      "         124       0.01      0.33      0.01        18\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.01      0.38      0.01        13\n",
      "         127       0.09      0.69      0.16       239\n",
      "         128       0.15      0.26      0.19       276\n",
      "         129       0.00      0.50      0.01         6\n",
      "         130       0.00      0.00      0.00        35\n",
      "         131       0.01      0.62      0.01        13\n",
      "         132       0.00      1.00      0.00         2\n",
      "         133       0.00      0.60      0.00         5\n",
      "         134       0.00      1.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.00      0.00      0.00        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.00      0.00      0.00        67\n",
      "         139       0.11      0.85      0.19       318\n",
      "         140       0.01      0.20      0.01        10\n",
      "         141       0.00      0.57      0.01         7\n",
      "\n",
      "   micro avg       0.03      0.51      0.05      9022\n",
      "   macro avg       0.03      0.45      0.04      9022\n",
      "weighted avg       0.11      0.51      0.16      9022\n",
      " samples avg       0.03      0.45      0.05      9022\n",
      "\n",
      "Time taken to run this cell : 0:00:00.917477\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs = -1)\n",
    "classifier.fit(x_train_char, y_train)\n",
    "predictions = classifier.predict(x_test_char)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:00:16.949097\n"
     ]
    }
   ],
   "source": [
    "vectorizer_char_2 = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='char', ngram_range=(2, 2),  max_features=20000)\n",
    "x_train_char_2 = vectorizer_char_2.fit_transform(train['cleaned'])\n",
    "x_test_char_2 = vectorizer_char_2.transform(test['cleaned'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.0\n",
      "Hamming loss  0.16552144966901883\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0699, Recall: 0.5466, F1-measure: 0.1239\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0435, Recall: 0.3455, F1-measure: 0.0714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.34      0.03        35\n",
      "           1       0.12      0.67      0.21       117\n",
      "           2       0.03      0.38      0.06        26\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.01      0.77      0.02        13\n",
      "           5       0.02      0.15      0.04        26\n",
      "           6       0.02      0.20      0.03        15\n",
      "           7       0.05      0.63      0.09        75\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.02      0.45      0.03        31\n",
      "          10       0.03      0.25      0.05         8\n",
      "          11       0.01      0.10      0.02        20\n",
      "          12       0.07      0.47      0.12        79\n",
      "          13       0.01      0.56      0.02         9\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.01      0.53      0.02        15\n",
      "          16       0.01      0.64      0.02        11\n",
      "          17       0.05      0.65      0.09       120\n",
      "          18       0.02      0.58      0.04        24\n",
      "          19       0.04      0.40      0.07        72\n",
      "          20       0.20      0.61      0.30       351\n",
      "          21       0.02      0.62      0.04        32\n",
      "          22       0.02      0.54      0.05        35\n",
      "          23       0.02      0.17      0.03        29\n",
      "          24       0.03      0.61      0.06        49\n",
      "          25       0.10      0.57      0.17       142\n",
      "          26       0.06      0.54      0.11        65\n",
      "          27       0.01      0.20      0.01        10\n",
      "          28       0.23      0.60      0.33       515\n",
      "          29       0.09      0.67      0.16        90\n",
      "          30       0.05      0.66      0.10        65\n",
      "          31       0.01      0.56      0.01         9\n",
      "          32       0.08      0.24      0.12        21\n",
      "          33       0.06      0.57      0.11        54\n",
      "          34       0.05      0.37      0.09        19\n",
      "          35       0.02      0.08      0.03        26\n",
      "          36       0.07      0.68      0.13        78\n",
      "          37       0.09      0.47      0.15       150\n",
      "          38       0.05      0.63      0.10        82\n",
      "          39       0.02      0.26      0.04        19\n",
      "          40       0.05      0.21      0.08        28\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.04      0.57      0.07        60\n",
      "          43       0.40      0.68      0.51       885\n",
      "          44       0.04      0.68      0.08        66\n",
      "          45       0.10      0.60      0.17       111\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.03      0.82      0.05        38\n",
      "          48       0.02      0.45      0.05        31\n",
      "          49       0.02      0.36      0.04        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.03      0.38      0.06        42\n",
      "          52       0.12      0.54      0.20       229\n",
      "          53       0.03      0.36      0.05        47\n",
      "          54       0.02      0.38      0.04         8\n",
      "          55       0.02      0.71      0.03        24\n",
      "          56       0.15      0.63      0.24       268\n",
      "          57       0.16      0.46      0.24       311\n",
      "          58       0.11      0.42      0.17       142\n",
      "          59       0.09      0.55      0.15       138\n",
      "          60       0.06      0.58      0.11        53\n",
      "          61       0.04      0.59      0.07        49\n",
      "          62       0.03      0.31      0.05        61\n",
      "          63       0.02      0.27      0.05        37\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.12      0.56      0.20       153\n",
      "          66       0.01      0.65      0.03        20\n",
      "          67       0.04      0.37      0.07        52\n",
      "          68       0.29      0.72      0.41       593\n",
      "          69       0.00      0.00      0.00         4\n",
      "          70       0.00      0.33      0.00         6\n",
      "          71       0.02      0.19      0.03        21\n",
      "          72       0.01      0.25      0.02        12\n",
      "          73       0.00      0.50      0.00         2\n",
      "          74       0.00      0.00      0.00        11\n",
      "          75       0.00      0.00      0.00         5\n",
      "          76       0.01      0.22      0.02         9\n",
      "          77       0.02      0.27      0.04        15\n",
      "          78       0.00      0.00      0.00         4\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.03      0.29      0.05        14\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.01      0.35      0.02        20\n",
      "          83       0.02      0.25      0.03        36\n",
      "          84       0.02      0.22      0.04         9\n",
      "          85       0.03      0.17      0.05         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.13      0.50      0.20       248\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.01      0.40      0.02        25\n",
      "          91       0.08      0.75      0.14       200\n",
      "          92       0.00      0.00      0.00         9\n",
      "          93       0.04      0.44      0.07        50\n",
      "          94       0.01      0.08      0.01        13\n",
      "          95       0.03      0.12      0.05        34\n",
      "          96       0.01      0.29      0.01        17\n",
      "          97       0.06      0.69      0.11        48\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.05      0.42      0.09        81\n",
      "         100       0.13      0.44      0.20       100\n",
      "         101       0.07      0.33      0.12        18\n",
      "         102       0.01      0.33      0.01         3\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.03      0.40      0.05        10\n",
      "         105       0.03      0.17      0.05         6\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.01      0.21      0.03        14\n",
      "         108       0.01      0.41      0.02        22\n",
      "         109       0.06      0.30      0.09        54\n",
      "         110       0.02      0.54      0.03        13\n",
      "         111       0.01      0.33      0.02        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.05      0.30      0.09        33\n",
      "         114       0.12      0.68      0.21       270\n",
      "         115       0.04      0.41      0.08        51\n",
      "         116       0.04      0.12      0.06        34\n",
      "         117       0.00      0.25      0.00         4\n",
      "         118       0.05      0.63      0.10        91\n",
      "         119       0.00      0.40      0.01         5\n",
      "         120       0.00      0.00      0.00        11\n",
      "         121       0.05      0.21      0.08        28\n",
      "         122       0.00      0.00      0.00         9\n",
      "         123       0.26      0.43      0.33       166\n",
      "         124       0.02      0.39      0.03        18\n",
      "         125       0.02      0.29      0.04         7\n",
      "         126       0.00      0.00      0.00        13\n",
      "         127       0.13      0.36      0.19       239\n",
      "         128       0.20      0.64      0.31       276\n",
      "         129       0.01      0.17      0.02         6\n",
      "         130       0.04      0.46      0.07        35\n",
      "         131       0.05      0.54      0.09        13\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         5\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.04      0.51      0.08        75\n",
      "         137       0.00      0.14      0.01         7\n",
      "         138       0.05      0.39      0.08        67\n",
      "         139       0.15      0.66      0.24       318\n",
      "         140       0.05      0.60      0.09        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.07      0.55      0.12      9022\n",
      "   macro avg       0.04      0.35      0.07      9022\n",
      "weighted avg       0.15      0.55      0.22      9022\n",
      " samples avg       0.07      0.53      0.12      9022\n",
      "\n",
      "Time taken to run this cell : 0:00:04.376459\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs = -1)\n",
    "classifier.fit(x_train_char_2, y_train)\n",
    "predictions = classifier.predict(x_test_char_2)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:00:25.395349\n"
     ]
    }
   ],
   "source": [
    "vectorizer_char_3 = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='char', ngram_range=(3, 3),  max_features=20000)\n",
    "x_train_char_3 = vectorizer_char_3.fit_transform(train['cleaned'])\n",
    "x_test_char_3 = vectorizer_char_3.transform(test['cleaned'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.0013486176668914363\n",
      "Hamming loss  0.08431947043013306\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1323, Recall: 0.5283, F1-measure: 0.2116\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0749, Recall: 0.2914, F1-measure: 0.1091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.11      0.03        35\n",
      "           1       0.13      0.78      0.23       117\n",
      "           2       0.10      0.38      0.16        26\n",
      "           3       0.05      0.09      0.07        11\n",
      "           4       0.07      0.31      0.11        13\n",
      "           5       0.04      0.46      0.07        26\n",
      "           6       0.03      0.40      0.06        15\n",
      "           7       0.06      0.52      0.11        75\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.05      0.13      0.07        31\n",
      "          10       0.11      0.50      0.18         8\n",
      "          11       0.01      0.05      0.01        20\n",
      "          12       0.06      0.51      0.11        79\n",
      "          13       0.09      0.11      0.10         9\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.03      0.20      0.06        15\n",
      "          16       0.02      0.27      0.03        11\n",
      "          17       0.08      0.48      0.13       120\n",
      "          18       0.18      0.08      0.11        24\n",
      "          19       0.06      0.38      0.10        72\n",
      "          20       0.25      0.58      0.35       351\n",
      "          21       0.08      0.31      0.13        32\n",
      "          22       0.03      0.29      0.06        35\n",
      "          23       0.02      0.21      0.04        29\n",
      "          24       0.05      0.39      0.09        49\n",
      "          25       0.11      0.47      0.18       142\n",
      "          26       0.17      0.48      0.25        65\n",
      "          27       0.04      0.30      0.07        10\n",
      "          28       0.28      0.55      0.37       515\n",
      "          29       0.13      0.73      0.22        90\n",
      "          30       0.11      0.75      0.19        65\n",
      "          31       0.05      0.11      0.07         9\n",
      "          32       0.08      0.57      0.14        21\n",
      "          33       0.11      0.54      0.18        54\n",
      "          34       0.05      0.42      0.09        19\n",
      "          35       0.04      0.35      0.08        26\n",
      "          36       0.14      0.73      0.23        78\n",
      "          37       0.10      0.60      0.18       150\n",
      "          38       0.10      0.54      0.17        82\n",
      "          39       0.20      0.11      0.14        19\n",
      "          40       0.06      0.32      0.10        28\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.06      0.28      0.10        60\n",
      "          43       0.48      0.69      0.57       885\n",
      "          44       0.07      0.56      0.13        66\n",
      "          45       0.18      0.59      0.28       111\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.06      0.45      0.11        38\n",
      "          48       0.04      0.32      0.07        31\n",
      "          49       0.05      0.33      0.08        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.07      0.52      0.13        42\n",
      "          52       0.15      0.53      0.23       229\n",
      "          53       0.09      0.30      0.13        47\n",
      "          54       0.03      0.25      0.05         8\n",
      "          55       0.04      0.29      0.06        24\n",
      "          56       0.19      0.59      0.29       268\n",
      "          57       0.19      0.63      0.29       311\n",
      "          58       0.12      0.60      0.20       142\n",
      "          59       0.12      0.57      0.20       138\n",
      "          60       0.10      0.77      0.18        53\n",
      "          61       0.06      0.51      0.11        49\n",
      "          62       0.04      0.20      0.06        61\n",
      "          63       0.03      0.35      0.06        37\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.14      0.63      0.24       153\n",
      "          66       0.04      0.15      0.06        20\n",
      "          67       0.05      0.29      0.09        52\n",
      "          68       0.38      0.68      0.48       593\n",
      "          69       0.00      0.00      0.00         4\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.05      0.14      0.07        21\n",
      "          72       0.09      0.17      0.12        12\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00        11\n",
      "          75       0.00      0.00      0.00         5\n",
      "          76       0.50      0.11      0.18         9\n",
      "          77       0.07      0.47      0.12        15\n",
      "          78       0.00      0.00      0.00         4\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.03      0.14      0.05        14\n",
      "          81       0.17      0.33      0.22         3\n",
      "          82       0.00      0.00      0.00        20\n",
      "          83       0.03      0.11      0.04        36\n",
      "          84       0.00      0.00      0.00         9\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.16      0.55      0.25       248\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.04      0.12      0.06        25\n",
      "          91       0.11      0.48      0.18       200\n",
      "          92       0.07      0.33      0.12         9\n",
      "          93       0.06      0.40      0.10        50\n",
      "          94       0.03      0.08      0.05        13\n",
      "          95       0.04      0.29      0.07        34\n",
      "          96       0.00      0.00      0.00        17\n",
      "          97       0.19      0.58      0.29        48\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.06      0.35      0.10        81\n",
      "         100       0.14      0.60      0.23       100\n",
      "         101       0.10      0.39      0.16        18\n",
      "         102       0.05      0.33      0.08         3\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.03      0.10      0.05        10\n",
      "         105       0.13      0.33      0.19         6\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.05      0.29      0.09        14\n",
      "         108       0.02      0.05      0.03        22\n",
      "         109       0.09      0.43      0.15        54\n",
      "         110       0.08      0.08      0.08        13\n",
      "         111       0.10      0.08      0.09        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.07      0.42      0.12        33\n",
      "         114       0.17      0.44      0.25       270\n",
      "         115       0.05      0.25      0.09        51\n",
      "         116       0.07      0.47      0.13        34\n",
      "         117       0.00      0.00      0.00         4\n",
      "         118       0.10      0.62      0.18        91\n",
      "         119       0.00      0.00      0.00         5\n",
      "         120       0.00      0.09      0.01        11\n",
      "         121       0.12      0.39      0.18        28\n",
      "         122       0.00      0.00      0.00         9\n",
      "         123       0.26      0.60      0.36       166\n",
      "         124       0.03      0.11      0.05        18\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.00      0.00      0.00        13\n",
      "         127       0.14      0.56      0.23       239\n",
      "         128       0.26      0.71      0.38       276\n",
      "         129       0.00      0.00      0.00         6\n",
      "         130       0.07      0.43      0.12        35\n",
      "         131       0.10      0.62      0.17        13\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         5\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.06      0.56      0.10        75\n",
      "         137       0.02      0.14      0.04         7\n",
      "         138       0.06      0.25      0.10        67\n",
      "         139       0.18      0.55      0.28       318\n",
      "         140       0.19      0.60      0.29        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.13      0.53      0.21      9022\n",
      "   macro avg       0.07      0.29      0.11      9022\n",
      "weighted avg       0.19      0.53      0.26      9022\n",
      " samples avg       0.14      0.51      0.20      9022\n",
      "\n",
      "Time taken to run this cell : 0:00:10.720298\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"),n_jobs = -1)\n",
    "classifier.fit(x_train_char_3, y_train)\n",
    "predictions = classifier.predict(x_test_char_3)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:00:39.478225\n"
     ]
    }
   ],
   "source": [
    "vectorizer_char_4 = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='char', ngram_range=(4, 4),  max_features=20000)\n",
    "x_train_char_4 = vectorizer_char_4.fit_transform(train['cleaned'])\n",
    "x_test_char_4 = vectorizer_char_4.transform(test['cleaned'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.0023600809170600135\n",
      "Hamming loss  0.06618911038720522\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1608, Recall: 0.4956, F1-measure: 0.2429\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0868, Recall: 0.2415, F1-measure: 0.1191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.06      0.03        35\n",
      "           1       0.16      0.68      0.26       117\n",
      "           2       0.10      0.27      0.15        26\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.19      0.23      0.21        13\n",
      "           5       0.09      0.23      0.13        26\n",
      "           6       0.07      0.20      0.11        15\n",
      "           7       0.07      0.43      0.12        75\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.11      0.13      0.12        31\n",
      "          10       0.25      0.50      0.33         8\n",
      "          11       0.00      0.00      0.00        20\n",
      "          12       0.06      0.41      0.11        79\n",
      "          13       0.25      0.11      0.15         9\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.04      0.07      0.05        15\n",
      "          16       0.05      0.27      0.08        11\n",
      "          17       0.09      0.36      0.15       120\n",
      "          18       0.12      0.08      0.10        24\n",
      "          19       0.09      0.29      0.13        72\n",
      "          20       0.24      0.64      0.35       351\n",
      "          21       0.07      0.09      0.08        32\n",
      "          22       0.03      0.17      0.06        35\n",
      "          23       0.03      0.03      0.03        29\n",
      "          24       0.06      0.35      0.10        49\n",
      "          25       0.12      0.43      0.19       142\n",
      "          26       0.19      0.46      0.27        65\n",
      "          27       0.04      0.10      0.06        10\n",
      "          28       0.27      0.61      0.37       515\n",
      "          29       0.15      0.74      0.25        90\n",
      "          30       0.14      0.71      0.24        65\n",
      "          31       0.11      0.11      0.11         9\n",
      "          32       0.20      0.52      0.29        21\n",
      "          33       0.12      0.46      0.19        54\n",
      "          34       0.08      0.26      0.12        19\n",
      "          35       0.08      0.15      0.11        26\n",
      "          36       0.15      0.69      0.25        78\n",
      "          37       0.13      0.45      0.20       150\n",
      "          38       0.10      0.55      0.18        82\n",
      "          39       0.20      0.05      0.08        19\n",
      "          40       0.13      0.29      0.18        28\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.06      0.32      0.10        60\n",
      "          43       0.50      0.68      0.58       885\n",
      "          44       0.09      0.47      0.15        66\n",
      "          45       0.15      0.72      0.25       111\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.10      0.39      0.15        38\n",
      "          48       0.06      0.32      0.09        31\n",
      "          49       0.06      0.18      0.09        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.15      0.40      0.22        42\n",
      "          52       0.16      0.49      0.24       229\n",
      "          53       0.13      0.30      0.18        47\n",
      "          54       0.03      0.12      0.05         8\n",
      "          55       0.06      0.29      0.10        24\n",
      "          56       0.20      0.60      0.30       268\n",
      "          57       0.20      0.52      0.29       311\n",
      "          58       0.15      0.56      0.23       142\n",
      "          59       0.15      0.43      0.22       138\n",
      "          60       0.13      0.68      0.21        53\n",
      "          61       0.08      0.33      0.13        49\n",
      "          62       0.04      0.23      0.07        61\n",
      "          63       0.04      0.11      0.06        37\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.16      0.63      0.25       153\n",
      "          66       0.20      0.15      0.17        20\n",
      "          67       0.07      0.29      0.11        52\n",
      "          68       0.38      0.70      0.49       593\n",
      "          69       0.00      0.00      0.00         4\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.00      0.00      0.00        21\n",
      "          72       0.17      0.17      0.17        12\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00        11\n",
      "          75       0.00      0.00      0.00         5\n",
      "          76       0.07      0.22      0.11         9\n",
      "          77       0.06      0.13      0.08        15\n",
      "          78       0.00      0.00      0.00         4\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.03      0.07      0.04        14\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.09      0.05      0.06        20\n",
      "          83       0.00      0.00      0.00        36\n",
      "          84       0.00      0.00      0.00         9\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.15      0.52      0.23       248\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.02      0.04      0.03        25\n",
      "          91       0.13      0.40      0.20       200\n",
      "          92       0.11      0.11      0.11         9\n",
      "          93       0.05      0.32      0.08        50\n",
      "          94       0.00      0.00      0.00        13\n",
      "          95       0.06      0.15      0.08        34\n",
      "          96       0.00      0.00      0.00        17\n",
      "          97       0.24      0.58      0.34        48\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.07      0.25      0.11        81\n",
      "         100       0.14      0.60      0.23       100\n",
      "         101       0.11      0.44      0.18        18\n",
      "         102       0.00      0.00      0.00         3\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.04      0.10      0.05        10\n",
      "         105       0.29      0.33      0.31         6\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.12      0.14      0.13        14\n",
      "         108       0.06      0.05      0.05        22\n",
      "         109       0.09      0.37      0.14        54\n",
      "         110       0.09      0.08      0.08        13\n",
      "         111       0.00      0.00      0.00        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.09      0.39      0.15        33\n",
      "         114       0.17      0.42      0.24       270\n",
      "         115       0.07      0.18      0.10        51\n",
      "         116       0.06      0.32      0.10        34\n",
      "         117       0.02      0.25      0.03         4\n",
      "         118       0.17      0.44      0.25        91\n",
      "         119       0.00      0.00      0.00         5\n",
      "         120       0.11      0.09      0.10        11\n",
      "         121       0.13      0.39      0.20        28\n",
      "         122       0.00      0.00      0.00         9\n",
      "         123       0.37      0.53      0.43       166\n",
      "         124       0.04      0.06      0.05        18\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.00      0.00      0.00        13\n",
      "         127       0.16      0.53      0.24       239\n",
      "         128       0.28      0.71      0.40       276\n",
      "         129       0.00      0.00      0.00         6\n",
      "         130       0.07      0.23      0.11        35\n",
      "         131       0.17      0.62      0.27        13\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         5\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.08      0.44      0.13        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.08      0.13      0.10        67\n",
      "         139       0.19      0.60      0.29       318\n",
      "         140       0.17      0.70      0.27        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.16      0.50      0.24      9022\n",
      "   macro avg       0.09      0.24      0.12      9022\n",
      "weighted avg       0.20      0.50      0.27      9022\n",
      " samples avg       0.16      0.48      0.22      9022\n",
      "\n",
      "Time taken to run this cell : 0:00:18.749642\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs = -1)\n",
    "classifier.fit(x_train_char_4, y_train)\n",
    "predictions = classifier.predict(x_test_char_4)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:00:54.500725\n"
     ]
    }
   ],
   "source": [
    "vectorizer_char_5 = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='char', ngram_range=(5, 5),  max_features=20000)\n",
    "x_train_char_5 = vectorizer_char_5.fit_transform(train['cleaned'])\n",
    "x_test_char_5 = vectorizer_char_5.transform(test['cleaned'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.004045853000674309\n",
      "Hamming loss  0.0652536255971432\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1637, Recall: 0.4980, F1-measure: 0.2464\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0878, Recall: 0.2492, F1-measure: 0.1177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.03      0.02        35\n",
      "           1       0.15      0.70      0.25       117\n",
      "           2       0.12      0.23      0.16        26\n",
      "           3       0.04      0.09      0.06        11\n",
      "           4       0.12      0.46      0.18        13\n",
      "           5       0.08      0.31      0.13        26\n",
      "           6       0.07      0.20      0.10        15\n",
      "           7       0.08      0.47      0.13        75\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.11      0.16      0.13        31\n",
      "          10       0.15      0.50      0.24         8\n",
      "          11       0.03      0.10      0.04        20\n",
      "          12       0.07      0.37      0.11        79\n",
      "          13       0.14      0.11      0.12         9\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.07      0.20      0.10        15\n",
      "          16       0.06      0.27      0.10        11\n",
      "          17       0.09      0.41      0.14       120\n",
      "          18       0.22      0.08      0.12        24\n",
      "          19       0.08      0.26      0.13        72\n",
      "          20       0.23      0.63      0.34       351\n",
      "          21       0.05      0.09      0.06        32\n",
      "          22       0.06      0.17      0.09        35\n",
      "          23       0.05      0.07      0.06        29\n",
      "          24       0.06      0.35      0.11        49\n",
      "          25       0.12      0.48      0.20       142\n",
      "          26       0.18      0.49      0.27        65\n",
      "          27       0.03      0.10      0.05        10\n",
      "          28       0.28      0.55      0.37       515\n",
      "          29       0.13      0.72      0.23        90\n",
      "          30       0.14      0.62      0.23        65\n",
      "          31       0.07      0.11      0.09         9\n",
      "          32       0.15      0.57      0.23        21\n",
      "          33       0.11      0.44      0.18        54\n",
      "          34       0.06      0.32      0.11        19\n",
      "          35       0.05      0.08      0.06        26\n",
      "          36       0.14      0.72      0.23        78\n",
      "          37       0.13      0.51      0.21       150\n",
      "          38       0.11      0.43      0.18        82\n",
      "          39       0.25      0.05      0.09        19\n",
      "          40       0.12      0.21      0.15        28\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.08      0.30      0.12        60\n",
      "          43       0.50      0.67      0.57       885\n",
      "          44       0.08      0.48      0.14        66\n",
      "          45       0.17      0.74      0.27       111\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.07      0.32      0.12        38\n",
      "          48       0.06      0.26      0.10        31\n",
      "          49       0.08      0.27      0.12        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.10      0.36      0.16        42\n",
      "          52       0.15      0.52      0.23       229\n",
      "          53       0.10      0.28      0.15        47\n",
      "          54       0.04      0.12      0.06         8\n",
      "          55       0.05      0.25      0.08        24\n",
      "          56       0.20      0.62      0.30       268\n",
      "          57       0.21      0.53      0.30       311\n",
      "          58       0.15      0.55      0.24       142\n",
      "          59       0.15      0.51      0.23       138\n",
      "          60       0.12      0.70      0.20        53\n",
      "          61       0.09      0.39      0.14        49\n",
      "          62       0.05      0.15      0.07        61\n",
      "          63       0.03      0.08      0.04        37\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.15      0.65      0.24       153\n",
      "          66       0.06      0.20      0.09        20\n",
      "          67       0.06      0.23      0.09        52\n",
      "          68       0.38      0.73      0.50       593\n",
      "          69       0.00      0.00      0.00         4\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.00      0.00      0.00        21\n",
      "          72       0.07      0.08      0.07        12\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00        11\n",
      "          75       0.00      0.00      0.00         5\n",
      "          76       0.50      0.11      0.18         9\n",
      "          77       0.11      0.53      0.19        15\n",
      "          78       0.00      0.00      0.00         4\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.04      0.07      0.05        14\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.17      0.05      0.08        20\n",
      "          83       0.03      0.06      0.04        36\n",
      "          84       0.00      0.00      0.00         9\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.16      0.51      0.24       248\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.06      0.08      0.07        25\n",
      "          91       0.11      0.32      0.17       200\n",
      "          92       0.08      0.11      0.09         9\n",
      "          93       0.06      0.34      0.10        50\n",
      "          94       0.00      0.00      0.00        13\n",
      "          95       0.04      0.09      0.06        34\n",
      "          96       0.00      0.00      0.00        17\n",
      "          97       0.20      0.62      0.31        48\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.07      0.25      0.11        81\n",
      "         100       0.15      0.61      0.25       100\n",
      "         101       0.12      0.44      0.19        18\n",
      "         102       0.00      0.00      0.00         3\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.10      0.10      0.10        10\n",
      "         105       0.22      0.33      0.27         6\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.12      0.07      0.09        14\n",
      "         108       0.09      0.05      0.06        22\n",
      "         109       0.10      0.37      0.16        54\n",
      "         110       0.00      0.00      0.00        13\n",
      "         111       0.12      0.08      0.10        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.10      0.39      0.16        33\n",
      "         114       0.18      0.53      0.27       270\n",
      "         115       0.05      0.22      0.08        51\n",
      "         116       0.07      0.47      0.12        34\n",
      "         117       0.00      0.00      0.00         4\n",
      "         118       0.16      0.40      0.23        91\n",
      "         119       0.00      0.00      0.00         5\n",
      "         120       0.20      0.09      0.13        11\n",
      "         121       0.14      0.39      0.21        28\n",
      "         122       0.00      0.00      0.00         9\n",
      "         123       0.32      0.57      0.41       166\n",
      "         124       0.04      0.06      0.05        18\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.00      0.00      0.00        13\n",
      "         127       0.16      0.51      0.25       239\n",
      "         128       0.28      0.72      0.40       276\n",
      "         129       0.02      0.50      0.03         6\n",
      "         130       0.09      0.20      0.12        35\n",
      "         131       0.14      0.62      0.22        13\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         5\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.07      0.45      0.12        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.06      0.15      0.08        67\n",
      "         139       0.19      0.58      0.28       318\n",
      "         140       0.14      0.70      0.24        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.16      0.50      0.25      9022\n",
      "   macro avg       0.09      0.25      0.12      9022\n",
      "weighted avg       0.20      0.50      0.27      9022\n",
      " samples avg       0.17      0.48      0.22      9022\n",
      "\n",
      "Time taken to run this cell : 0:00:13.817933\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs = -1)\n",
    "classifier.fit(x_train_char_5, y_train)\n",
    "predictions = classifier.predict(x_test_char_5)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:01:03.154397\n"
     ]
    }
   ],
   "source": [
    "vectorizer_char_6 = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='char', ngram_range=(6, 6),  max_features=20000)\n",
    "x_train_char_6 = vectorizer_char_6.fit_transform(train['cleaned'])\n",
    "x_test_char_6 = vectorizer_char_6.transform(test['cleaned'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.0016857720836142953\n",
      "Hamming loss  0.06522275934772492\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1621, Recall: 0.4905, F1-measure: 0.2437\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0893, Recall: 0.2404, F1-measure: 0.1189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.09      0.04        35\n",
      "           1       0.16      0.70      0.26       117\n",
      "           2       0.11      0.23      0.15        26\n",
      "           3       0.03      0.09      0.05        11\n",
      "           4       0.05      0.15      0.08        13\n",
      "           5       0.08      0.35      0.12        26\n",
      "           6       0.09      0.27      0.13        15\n",
      "           7       0.08      0.43      0.13        75\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.12      0.13      0.12        31\n",
      "          10       0.17      0.50      0.26         8\n",
      "          11       0.03      0.05      0.03        20\n",
      "          12       0.07      0.33      0.11        79\n",
      "          13       0.10      0.11      0.11         9\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.09      0.13      0.11        15\n",
      "          16       0.08      0.18      0.11        11\n",
      "          17       0.10      0.33      0.15       120\n",
      "          18       0.33      0.08      0.13        24\n",
      "          19       0.09      0.22      0.12        72\n",
      "          20       0.23      0.61      0.33       351\n",
      "          21       0.06      0.09      0.07        32\n",
      "          22       0.04      0.09      0.06        35\n",
      "          23       0.03      0.10      0.05        29\n",
      "          24       0.07      0.35      0.12        49\n",
      "          25       0.12      0.43      0.19       142\n",
      "          26       0.18      0.46      0.25        65\n",
      "          27       0.06      0.20      0.09        10\n",
      "          28       0.28      0.55      0.38       515\n",
      "          29       0.14      0.70      0.23        90\n",
      "          30       0.15      0.65      0.24        65\n",
      "          31       0.06      0.11      0.08         9\n",
      "          32       0.12      0.52      0.19        21\n",
      "          33       0.11      0.41      0.17        54\n",
      "          34       0.07      0.32      0.12        19\n",
      "          35       0.05      0.08      0.06        26\n",
      "          36       0.14      0.68      0.23        78\n",
      "          37       0.13      0.53      0.21       150\n",
      "          38       0.12      0.44      0.19        82\n",
      "          39       0.25      0.05      0.09        19\n",
      "          40       0.07      0.11      0.09        28\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.08      0.37      0.13        60\n",
      "          43       0.50      0.68      0.58       885\n",
      "          44       0.08      0.39      0.13        66\n",
      "          45       0.17      0.74      0.28       111\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.07      0.42      0.12        38\n",
      "          48       0.07      0.29      0.11        31\n",
      "          49       0.08      0.30      0.13        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.16      0.38      0.22        42\n",
      "          52       0.15      0.53      0.23       229\n",
      "          53       0.09      0.28      0.14        47\n",
      "          54       0.07      0.12      0.09         8\n",
      "          55       0.05      0.17      0.07        24\n",
      "          56       0.21      0.62      0.31       268\n",
      "          57       0.20      0.55      0.30       311\n",
      "          58       0.14      0.53      0.22       142\n",
      "          59       0.15      0.49      0.23       138\n",
      "          60       0.12      0.66      0.20        53\n",
      "          61       0.09      0.37      0.15        49\n",
      "          62       0.04      0.16      0.07        61\n",
      "          63       0.03      0.11      0.05        37\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.16      0.65      0.25       153\n",
      "          66       0.18      0.20      0.19        20\n",
      "          67       0.06      0.23      0.10        52\n",
      "          68       0.39      0.72      0.50       593\n",
      "          69       0.15      0.50      0.24         4\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.00      0.00      0.00        21\n",
      "          72       0.06      0.08      0.07        12\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00        11\n",
      "          75       0.00      0.00      0.00         5\n",
      "          76       0.08      0.11      0.09         9\n",
      "          77       0.10      0.40      0.16        15\n",
      "          78       0.00      0.00      0.00         4\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.05      0.07      0.06        14\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.17      0.05      0.08        20\n",
      "          83       0.01      0.03      0.02        36\n",
      "          84       0.00      0.00      0.00         9\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.16      0.46      0.24       248\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.02      0.04      0.03        25\n",
      "          91       0.11      0.39      0.17       200\n",
      "          92       0.20      0.11      0.14         9\n",
      "          93       0.05      0.30      0.09        50\n",
      "          94       0.33      0.08      0.12        13\n",
      "          95       0.05      0.15      0.07        34\n",
      "          96       0.00      0.00      0.00        17\n",
      "          97       0.20      0.54      0.30        48\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.06      0.22      0.10        81\n",
      "         100       0.14      0.59      0.23       100\n",
      "         101       0.10      0.39      0.16        18\n",
      "         102       0.00      0.00      0.00         3\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.15      0.30      0.20        10\n",
      "         105       0.22      0.33      0.27         6\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.30      0.21      0.25        14\n",
      "         108       0.08      0.05      0.06        22\n",
      "         109       0.08      0.30      0.13        54\n",
      "         110       0.00      0.00      0.00        13\n",
      "         111       0.10      0.08      0.09        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.07      0.39      0.12        33\n",
      "         114       0.18      0.53      0.27       270\n",
      "         115       0.04      0.18      0.07        51\n",
      "         116       0.07      0.47      0.11        34\n",
      "         117       0.00      0.00      0.00         4\n",
      "         118       0.15      0.37      0.21        91\n",
      "         119       0.00      0.00      0.00         5\n",
      "         120       0.00      0.00      0.00        11\n",
      "         121       0.14      0.25      0.18        28\n",
      "         122       0.00      0.00      0.00         9\n",
      "         123       0.29      0.57      0.39       166\n",
      "         124       0.03      0.06      0.04        18\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.00      0.00      0.00        13\n",
      "         127       0.17      0.46      0.25       239\n",
      "         128       0.27      0.72      0.39       276\n",
      "         129       0.00      0.00      0.00         6\n",
      "         130       0.09      0.26      0.14        35\n",
      "         131       0.10      0.54      0.16        13\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         5\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.08      0.43      0.13        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.06      0.15      0.09        67\n",
      "         139       0.19      0.59      0.29       318\n",
      "         140       0.15      0.60      0.24        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.16      0.49      0.24      9022\n",
      "   macro avg       0.09      0.24      0.12      9022\n",
      "weighted avg       0.20      0.49      0.27      9022\n",
      " samples avg       0.16      0.48      0.21      9022\n",
      "\n",
      "Time taken to run this cell : 0:00:16.396769\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs = -1)\n",
    "classifier.fit(x_train_char_6, y_train)\n",
    "predictions = classifier.predict(x_test_char_6)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:01:26.100191\n"
     ]
    }
   ],
   "source": [
    "vectorizer_char_8 = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='char', ngram_range=(7, 7),  max_features=20000)\n",
    "x_train_char_8 = vectorizer_char_8.fit_transform(train['cleaned'])\n",
    "x_test_char_8 = vectorizer_char_8.transform(test['cleaned'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.0020229265003371545\n",
      "Hamming loss  0.0618963273911846\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1687, Recall: 0.4809, F1-measure: 0.2497\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0973, Recall: 0.2290, F1-measure: 0.1194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.03      0.02        35\n",
      "           1       0.16      0.69      0.26       117\n",
      "           2       0.16      0.23      0.19        26\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.11      0.31      0.16        13\n",
      "           5       0.09      0.38      0.15        26\n",
      "           6       0.06      0.20      0.09        15\n",
      "           7       0.08      0.41      0.14        75\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.12      0.16      0.14        31\n",
      "          10       0.17      0.50      0.25         8\n",
      "          11       0.00      0.00      0.00        20\n",
      "          12       0.07      0.32      0.12        79\n",
      "          13       0.08      0.11      0.10         9\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.14      0.13      0.14        15\n",
      "          16       0.09      0.27      0.13        11\n",
      "          17       0.09      0.32      0.14       120\n",
      "          18       0.25      0.04      0.07        24\n",
      "          19       0.11      0.25      0.15        72\n",
      "          20       0.23      0.59      0.33       351\n",
      "          21       0.09      0.16      0.12        32\n",
      "          22       0.03      0.09      0.05        35\n",
      "          23       0.04      0.10      0.06        29\n",
      "          24       0.06      0.24      0.10        49\n",
      "          25       0.12      0.38      0.19       142\n",
      "          26       0.19      0.49      0.27        65\n",
      "          27       0.00      0.00      0.00        10\n",
      "          28       0.30      0.56      0.39       515\n",
      "          29       0.15      0.69      0.24        90\n",
      "          30       0.15      0.63      0.24        65\n",
      "          31       0.06      0.11      0.08         9\n",
      "          32       0.12      0.48      0.19        21\n",
      "          33       0.12      0.41      0.18        54\n",
      "          34       0.09      0.26      0.13        19\n",
      "          35       0.07      0.08      0.07        26\n",
      "          36       0.15      0.67      0.24        78\n",
      "          37       0.14      0.51      0.22       150\n",
      "          38       0.12      0.45      0.19        82\n",
      "          39       0.25      0.05      0.09        19\n",
      "          40       0.13      0.18      0.15        28\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.09      0.32      0.13        60\n",
      "          43       0.50      0.68      0.58       885\n",
      "          44       0.08      0.36      0.13        66\n",
      "          45       0.18      0.73      0.29       111\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.09      0.37      0.14        38\n",
      "          48       0.09      0.29      0.13        31\n",
      "          49       0.09      0.27      0.13        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.14      0.36      0.20        42\n",
      "          52       0.15      0.49      0.23       229\n",
      "          53       0.13      0.30      0.18        47\n",
      "          54       0.00      0.00      0.00         8\n",
      "          55       0.04      0.17      0.06        24\n",
      "          56       0.21      0.65      0.31       268\n",
      "          57       0.20      0.52      0.29       311\n",
      "          58       0.15      0.51      0.23       142\n",
      "          59       0.15      0.46      0.23       138\n",
      "          60       0.12      0.64      0.20        53\n",
      "          61       0.09      0.33      0.14        49\n",
      "          62       0.04      0.13      0.06        61\n",
      "          63       0.03      0.08      0.05        37\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.15      0.61      0.24       153\n",
      "          66       0.14      0.20      0.17        20\n",
      "          67       0.05      0.17      0.08        52\n",
      "          68       0.40      0.71      0.51       593\n",
      "          69       0.00      0.00      0.00         4\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.00      0.00      0.00        21\n",
      "          72       0.12      0.17      0.14        12\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00        11\n",
      "          75       0.00      0.00      0.00         5\n",
      "          76       1.00      0.11      0.20         9\n",
      "          77       0.12      0.47      0.19        15\n",
      "          78       0.00      0.00      0.00         4\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.04      0.07      0.05        14\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.12      0.05      0.07        20\n",
      "          83       0.00      0.00      0.00        36\n",
      "          84       0.00      0.00      0.00         9\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.17      0.51      0.25       248\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.06      0.08      0.07        25\n",
      "          91       0.11      0.39      0.17       200\n",
      "          92       0.00      0.00      0.00         9\n",
      "          93       0.06      0.30      0.09        50\n",
      "          94       0.50      0.08      0.13        13\n",
      "          95       0.05      0.15      0.07        34\n",
      "          96       0.00      0.00      0.00        17\n",
      "          97       0.20      0.54      0.30        48\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.05      0.16      0.08        81\n",
      "         100       0.14      0.56      0.23       100\n",
      "         101       0.09      0.33      0.15        18\n",
      "         102       0.14      0.33      0.20         3\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.14      0.10      0.12        10\n",
      "         105       0.33      0.33      0.33         6\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.31      0.29      0.30        14\n",
      "         108       0.09      0.05      0.06        22\n",
      "         109       0.08      0.28      0.12        54\n",
      "         110       0.06      0.08      0.06        13\n",
      "         111       0.08      0.08      0.08        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.08      0.33      0.13        33\n",
      "         114       0.18      0.49      0.26       270\n",
      "         115       0.04      0.14      0.06        51\n",
      "         116       0.07      0.44      0.11        34\n",
      "         117       0.00      0.00      0.00         4\n",
      "         118       0.16      0.40      0.23        91\n",
      "         119       0.00      0.00      0.00         5\n",
      "         120       0.00      0.00      0.00        11\n",
      "         121       0.11      0.18      0.14        28\n",
      "         122       0.00      0.00      0.00         9\n",
      "         123       0.30      0.54      0.39       166\n",
      "         124       0.00      0.00      0.00        18\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.00      0.00      0.00        13\n",
      "         127       0.17      0.49      0.25       239\n",
      "         128       0.26      0.73      0.39       276\n",
      "         129       0.00      0.00      0.00         6\n",
      "         130       0.08      0.17      0.11        35\n",
      "         131       0.15      0.62      0.24        13\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         5\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.08      0.47      0.14        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.06      0.12      0.08        67\n",
      "         139       0.19      0.58      0.29       318\n",
      "         140       0.12      0.50      0.20        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.17      0.48      0.25      9022\n",
      "   macro avg       0.10      0.23      0.12      9022\n",
      "weighted avg       0.21      0.48      0.28      9022\n",
      " samples avg       0.17      0.47      0.22      9022\n",
      "\n",
      "Time taken to run this cell : 0:00:12.065423\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs = -1)\n",
    "classifier.fit(x_train_char_8, y_train)\n",
    "predictions = classifier.predict(x_test_char_8)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:03:24.349316\n"
     ]
    }
   ],
   "source": [
    "vectorizer_charngram = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='char', ngram_range=(1, 6),  max_features=20000)\n",
    "x_train_charngram = vectorizer_charngram.fit_transform(train['cleaned'])\n",
    "x_test_charngram = vectorizer_charngram.transform(test['cleaned'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.004045853000674309\n",
      "Hamming loss  0.08361666967414738\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1341, Recall: 0.5318, F1-measure: 0.2141\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0731, Recall: 0.3132, F1-measure: 0.1114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.11      0.04        35\n",
      "           1       0.14      0.74      0.23       117\n",
      "           2       0.05      0.42      0.08        26\n",
      "           3       0.02      0.27      0.03        11\n",
      "           4       0.06      0.31      0.11        13\n",
      "           5       0.04      0.42      0.07        26\n",
      "           6       0.03      0.33      0.05        15\n",
      "           7       0.08      0.55      0.14        75\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.04      0.19      0.07        31\n",
      "          10       0.08      0.50      0.14         8\n",
      "          11       0.02      0.15      0.04        20\n",
      "          12       0.06      0.46      0.11        79\n",
      "          13       0.02      0.22      0.04         9\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.04      0.33      0.07        15\n",
      "          16       0.02      0.27      0.03        11\n",
      "          17       0.08      0.38      0.14       120\n",
      "          18       0.02      0.08      0.03        24\n",
      "          19       0.07      0.22      0.11        72\n",
      "          20       0.23      0.60      0.33       351\n",
      "          21       0.06      0.38      0.10        32\n",
      "          22       0.04      0.31      0.07        35\n",
      "          23       0.02      0.21      0.04        29\n",
      "          24       0.06      0.41      0.10        49\n",
      "          25       0.11      0.49      0.18       142\n",
      "          26       0.15      0.62      0.24        65\n",
      "          27       0.02      0.30      0.04        10\n",
      "          28       0.28      0.56      0.37       515\n",
      "          29       0.11      0.78      0.19        90\n",
      "          30       0.10      0.75      0.17        65\n",
      "          31       0.05      0.11      0.07         9\n",
      "          32       0.07      0.57      0.13        21\n",
      "          33       0.09      0.59      0.15        54\n",
      "          34       0.06      0.37      0.11        19\n",
      "          35       0.05      0.15      0.08        26\n",
      "          36       0.11      0.72      0.20        78\n",
      "          37       0.11      0.61      0.19       150\n",
      "          38       0.09      0.55      0.15        82\n",
      "          39       0.08      0.37      0.13        19\n",
      "          40       0.05      0.46      0.09        28\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.06      0.42      0.11        60\n",
      "          43       0.51      0.65      0.57       885\n",
      "          44       0.08      0.58      0.15        66\n",
      "          45       0.15      0.76      0.25       111\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.06      0.50      0.11        38\n",
      "          48       0.03      0.32      0.05        31\n",
      "          49       0.05      0.42      0.09        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.09      0.50      0.15        42\n",
      "          52       0.15      0.57      0.24       229\n",
      "          53       0.07      0.38      0.11        47\n",
      "          54       0.00      0.12      0.01         8\n",
      "          55       0.05      0.21      0.08        24\n",
      "          56       0.18      0.67      0.28       268\n",
      "          57       0.20      0.52      0.29       311\n",
      "          58       0.15      0.50      0.23       142\n",
      "          59       0.11      0.62      0.19       138\n",
      "          60       0.10      0.68      0.18        53\n",
      "          61       0.07      0.45      0.12        49\n",
      "          62       0.04      0.15      0.06        61\n",
      "          63       0.04      0.41      0.07        37\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.14      0.69      0.24       153\n",
      "          66       0.06      0.30      0.09        20\n",
      "          67       0.07      0.38      0.12        52\n",
      "          68       0.37      0.72      0.49       593\n",
      "          69       0.33      0.25      0.29         4\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.00      0.00      0.00        21\n",
      "          72       0.08      0.17      0.11        12\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00        11\n",
      "          75       0.33      0.20      0.25         5\n",
      "          76       0.05      0.11      0.07         9\n",
      "          77       0.11      0.53      0.19        15\n",
      "          78       0.00      0.00      0.00         4\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.05      0.21      0.08        14\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.03      0.10      0.05        20\n",
      "          83       0.03      0.17      0.05        36\n",
      "          84       0.04      0.33      0.07         9\n",
      "          85       0.08      0.50      0.14         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.15      0.56      0.23       248\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.02      0.12      0.04        25\n",
      "          91       0.11      0.42      0.18       200\n",
      "          92       0.09      0.33      0.14         9\n",
      "          93       0.05      0.38      0.09        50\n",
      "          94       0.00      0.00      0.00        13\n",
      "          95       0.04      0.35      0.07        34\n",
      "          96       0.01      0.06      0.02        17\n",
      "          97       0.15      0.62      0.24        48\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.07      0.33      0.12        81\n",
      "         100       0.14      0.61      0.22       100\n",
      "         101       0.10      0.44      0.17        18\n",
      "         102       0.22      0.67      0.33         3\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.04      0.10      0.06        10\n",
      "         105       0.06      0.33      0.11         6\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.08      0.36      0.13        14\n",
      "         108       0.04      0.09      0.05        22\n",
      "         109       0.08      0.48      0.14        54\n",
      "         110       0.03      0.08      0.04        13\n",
      "         111       0.00      0.00      0.00        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.07      0.45      0.12        33\n",
      "         114       0.17      0.55      0.26       270\n",
      "         115       0.05      0.31      0.08        51\n",
      "         116       0.05      0.47      0.10        34\n",
      "         117       0.00      0.00      0.00         4\n",
      "         118       0.16      0.47      0.24        91\n",
      "         119       0.00      0.00      0.00         5\n",
      "         120       0.00      0.00      0.00        11\n",
      "         121       0.08      0.43      0.14        28\n",
      "         122       0.03      0.11      0.05         9\n",
      "         123       0.29      0.59      0.39       166\n",
      "         124       0.05      0.17      0.08        18\n",
      "         125       0.07      0.14      0.09         7\n",
      "         126       0.01      0.08      0.02        13\n",
      "         127       0.17      0.47      0.25       239\n",
      "         128       0.26      0.74      0.39       276\n",
      "         129       0.00      0.00      0.00         6\n",
      "         130       0.08      0.31      0.12        35\n",
      "         131       0.08      0.69      0.15        13\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         5\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.07      0.52      0.12        75\n",
      "         137       0.02      0.14      0.03         7\n",
      "         138       0.04      0.25      0.08        67\n",
      "         139       0.19      0.56      0.28       318\n",
      "         140       0.12      0.70      0.21        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.13      0.53      0.21      9022\n",
      "   macro avg       0.07      0.31      0.11      9022\n",
      "weighted avg       0.19      0.53      0.26      9022\n",
      " samples avg       0.14      0.51      0.20      9022\n",
      "\n",
      "Time taken to run this cell : 0:00:31.320822\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs = -1)\n",
    "classifier.fit(x_train_charngram, y_train)\n",
    "predictions = classifier.predict(x_test_charngram)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:01:45.282984\n"
     ]
    }
   ],
   "source": [
    "vectorizer_charngram = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='char', ngram_range=(2, 4),  max_features=20000)\n",
    "x_train_charngram = vectorizer_charngram.fit_transform(train['cleaned'])\n",
    "x_test_charngram = vectorizer_charngram.transform(test['cleaned'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.0006743088334457181\n",
      "Hamming loss  0.07980824936130607\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1383, Recall: 0.5211, F1-measure: 0.2186\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0789, Recall: 0.2743, F1-measure: 0.1131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.09      0.03        35\n",
      "           1       0.16      0.71      0.27       117\n",
      "           2       0.08      0.38      0.14        26\n",
      "           3       0.05      0.27      0.09        11\n",
      "           4       0.04      0.38      0.08        13\n",
      "           5       0.03      0.38      0.06        26\n",
      "           6       0.04      0.20      0.06        15\n",
      "           7       0.07      0.47      0.12        75\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.05      0.13      0.08        31\n",
      "          10       0.18      0.50      0.27         8\n",
      "          11       0.02      0.15      0.04        20\n",
      "          12       0.07      0.48      0.12        79\n",
      "          13       0.03      0.33      0.05         9\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.06      0.20      0.09        15\n",
      "          16       0.05      0.27      0.09        11\n",
      "          17       0.08      0.47      0.14       120\n",
      "          18       0.04      0.08      0.06        24\n",
      "          19       0.06      0.26      0.10        72\n",
      "          20       0.24      0.61      0.34       351\n",
      "          21       0.07      0.09      0.08        32\n",
      "          22       0.04      0.29      0.07        35\n",
      "          23       0.05      0.07      0.06        29\n",
      "          24       0.06      0.35      0.11        49\n",
      "          25       0.11      0.49      0.18       142\n",
      "          26       0.17      0.54      0.25        65\n",
      "          27       0.03      0.30      0.05        10\n",
      "          28       0.27      0.57      0.37       515\n",
      "          29       0.13      0.71      0.22        90\n",
      "          30       0.11      0.77      0.19        65\n",
      "          31       0.02      0.11      0.03         9\n",
      "          32       0.12      0.52      0.19        21\n",
      "          33       0.12      0.48      0.19        54\n",
      "          34       0.05      0.32      0.08        19\n",
      "          35       0.05      0.15      0.07        26\n",
      "          36       0.14      0.72      0.23        78\n",
      "          37       0.12      0.53      0.19       150\n",
      "          38       0.10      0.56      0.17        82\n",
      "          39       0.12      0.05      0.07        19\n",
      "          40       0.09      0.32      0.15        28\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.06      0.35      0.11        60\n",
      "          43       0.50      0.69      0.58       885\n",
      "          44       0.08      0.53      0.13        66\n",
      "          45       0.17      0.68      0.27       111\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.07      0.55      0.13        38\n",
      "          48       0.04      0.26      0.07        31\n",
      "          49       0.07      0.27      0.11        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.13      0.40      0.19        42\n",
      "          52       0.14      0.55      0.23       229\n",
      "          53       0.07      0.40      0.12        47\n",
      "          54       0.02      0.12      0.04         8\n",
      "          55       0.05      0.46      0.08        24\n",
      "          56       0.19      0.63      0.29       268\n",
      "          57       0.18      0.66      0.28       311\n",
      "          58       0.15      0.51      0.24       142\n",
      "          59       0.13      0.51      0.21       138\n",
      "          60       0.11      0.70      0.19        53\n",
      "          61       0.06      0.43      0.11        49\n",
      "          62       0.04      0.23      0.06        61\n",
      "          63       0.04      0.27      0.06        37\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.15      0.63      0.25       153\n",
      "          66       0.05      0.15      0.07        20\n",
      "          67       0.07      0.21      0.10        52\n",
      "          68       0.37      0.69      0.48       593\n",
      "          69       0.33      0.25      0.29         4\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.03      0.05      0.04        21\n",
      "          72       0.14      0.17      0.15        12\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00        11\n",
      "          75       0.00      0.00      0.00         5\n",
      "          76       0.08      0.11      0.10         9\n",
      "          77       0.13      0.33      0.19        15\n",
      "          78       0.00      0.00      0.00         4\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.04      0.21      0.06        14\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.00      0.00      0.00        20\n",
      "          83       0.01      0.06      0.02        36\n",
      "          84       0.00      0.00      0.00         9\n",
      "          85       0.04      0.17      0.06         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.17      0.46      0.25       248\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.00      0.00      0.00        25\n",
      "          91       0.11      0.52      0.19       200\n",
      "          92       0.12      0.11      0.12         9\n",
      "          93       0.05      0.34      0.09        50\n",
      "          94       0.33      0.08      0.12        13\n",
      "          95       0.05      0.18      0.08        34\n",
      "          96       0.02      0.12      0.04        17\n",
      "          97       0.22      0.60      0.32        48\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.06      0.35      0.11        81\n",
      "         100       0.15      0.61      0.23       100\n",
      "         101       0.12      0.39      0.19        18\n",
      "         102       0.00      0.00      0.00         3\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.12      0.10      0.11        10\n",
      "         105       0.11      0.33      0.17         6\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.13      0.14      0.14        14\n",
      "         108       0.06      0.05      0.05        22\n",
      "         109       0.08      0.37      0.13        54\n",
      "         110       0.06      0.08      0.07        13\n",
      "         111       0.15      0.17      0.16        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.07      0.45      0.13        33\n",
      "         114       0.17      0.47      0.25       270\n",
      "         115       0.05      0.35      0.08        51\n",
      "         116       0.05      0.44      0.09        34\n",
      "         117       0.00      0.00      0.00         4\n",
      "         118       0.14      0.52      0.22        91\n",
      "         119       0.00      0.00      0.00         5\n",
      "         120       0.00      0.00      0.00        11\n",
      "         121       0.12      0.39      0.19        28\n",
      "         122       0.00      0.00      0.00         9\n",
      "         123       0.28      0.58      0.38       166\n",
      "         124       0.05      0.06      0.05        18\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.00      0.00      0.00        13\n",
      "         127       0.16      0.51      0.25       239\n",
      "         128       0.26      0.74      0.39       276\n",
      "         129       0.00      0.00      0.00         6\n",
      "         130       0.07      0.31      0.12        35\n",
      "         131       0.09      0.62      0.15        13\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         5\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.06      0.48      0.11        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.06      0.13      0.09        67\n",
      "         139       0.18      0.64      0.29       318\n",
      "         140       0.16      0.70      0.26        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.14      0.52      0.22      9022\n",
      "   macro avg       0.08      0.27      0.11      9022\n",
      "weighted avg       0.19      0.52      0.27      9022\n",
      " samples avg       0.14      0.50      0.20      9022\n",
      "\n",
      "Time taken to run this cell : 0:00:34.987293\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs = -1)\n",
    "classifier.fit(x_train_charngram, y_train)\n",
    "predictions = classifier.predict(x_test_charngram)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = hstack((x_train_multilabel_bigram, x_train_char_5),format=\"csr\",dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1 = hstack((x_test_multilabel_bigram, x_test_char_5),format=\"csr\",dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = x_train_1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = x_test_1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_6 = np.hstack((train, train_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_6 = np.hstack((test, test_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('final_train_for_every_important_feature.npy', x_train_6)\n",
    "np.save('final_test_for_every_important_feature.npy', x_test_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.0050573162508428865\n",
      "Hamming loss  0.08043744598406352\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1693, Recall: 0.7054, F1-measure: 0.2731\n",
      "Macro-average quality numbers\n",
      "Precision: 0.1557, Recall: 0.6540, F1-measure: 0.2236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.69      0.10        35\n",
      "           1       0.18      0.76      0.30       117\n",
      "           2       0.76      1.00      0.87        26\n",
      "           3       0.01      0.27      0.02        11\n",
      "           4       0.11      0.85      0.20        13\n",
      "           5       0.19      1.00      0.31        26\n",
      "           6       0.08      0.80      0.15        15\n",
      "           7       0.12      0.72      0.21        75\n",
      "           8       0.01      0.25      0.01         4\n",
      "           9       0.24      1.00      0.38        31\n",
      "          10       0.17      0.88      0.29         8\n",
      "          11       0.03      0.45      0.05        20\n",
      "          12       0.07      0.76      0.13        79\n",
      "          13       0.03      0.56      0.06         9\n",
      "          14       0.04      1.00      0.08         3\n",
      "          15       0.06      0.40      0.10        15\n",
      "          16       0.04      0.64      0.07        11\n",
      "          17       0.21      0.22      0.21       120\n",
      "          18       0.14      0.54      0.22        24\n",
      "          19       0.06      0.56      0.10        72\n",
      "          20       0.37      0.59      0.45       351\n",
      "          21       0.08      0.69      0.14        32\n",
      "          22       0.03      0.31      0.05        35\n",
      "          23       0.04      0.28      0.07        29\n",
      "          24       0.07      0.67      0.13        49\n",
      "          25       0.42      0.79      0.55       142\n",
      "          26       0.13      0.66      0.22        65\n",
      "          27       0.07      0.40      0.12        10\n",
      "          28       0.60      0.85      0.70       515\n",
      "          29       0.51      1.00      0.67        90\n",
      "          30       0.10      0.49      0.16        65\n",
      "          31       0.16      1.00      0.27         9\n",
      "          32       0.08      0.62      0.14        21\n",
      "          33       0.22      0.69      0.34        54\n",
      "          34       0.22      0.95      0.35        19\n",
      "          35       0.84      1.00      0.91        26\n",
      "          36       0.18      0.68      0.28        78\n",
      "          37       0.15      0.73      0.24       150\n",
      "          38       0.15      0.61      0.24        82\n",
      "          39       0.05      0.37      0.09        19\n",
      "          40       0.12      0.18      0.14        28\n",
      "          41       0.07      1.00      0.12         5\n",
      "          42       0.25      0.72      0.37        60\n",
      "          43       0.54      0.80      0.64       885\n",
      "          44       0.09      0.70      0.16        66\n",
      "          45       0.50      1.00      0.66       111\n",
      "          46       0.00      1.00      0.00         1\n",
      "          47       0.11      0.63      0.19        38\n",
      "          48       0.10      0.39      0.16        31\n",
      "          49       0.28      0.97      0.43        33\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.74      0.93      0.82        42\n",
      "          52       0.20      0.71      0.31       229\n",
      "          53       0.07      0.34      0.11        47\n",
      "          54       0.10      0.88      0.18         8\n",
      "          55       0.05      0.67      0.10        24\n",
      "          56       0.31      0.81      0.45       268\n",
      "          57       0.25      0.86      0.38       311\n",
      "          58       0.69      0.83      0.75       142\n",
      "          59       0.19      0.60      0.29       138\n",
      "          60       0.73      0.92      0.82        53\n",
      "          61       0.52      0.82      0.63        49\n",
      "          62       0.23      0.67      0.34        61\n",
      "          63       0.10      0.62      0.17        37\n",
      "          64       0.01      0.50      0.02         6\n",
      "          65       0.21      0.61      0.32       153\n",
      "          66       0.03      0.50      0.06        20\n",
      "          67       0.09      0.75      0.16        52\n",
      "          68       0.58      0.74      0.65       593\n",
      "          69       0.01      0.50      0.02         4\n",
      "          70       0.00      0.17      0.01         6\n",
      "          71       0.06      0.38      0.10        21\n",
      "          72       0.14      0.83      0.24        12\n",
      "          73       0.02      1.00      0.03         2\n",
      "          74       0.08      0.27      0.13        11\n",
      "          75       0.02      1.00      0.04         5\n",
      "          76       0.22      1.00      0.36         9\n",
      "          77       0.50      0.93      0.65        15\n",
      "          78       0.15      0.75      0.25         4\n",
      "          79       0.01      0.50      0.03         4\n",
      "          80       0.11      1.00      0.20        14\n",
      "          81       0.01      0.33      0.02         3\n",
      "          82       0.10      0.40      0.15        20\n",
      "          83       0.05      0.50      0.09        36\n",
      "          84       0.02      0.22      0.04         9\n",
      "          85       0.06      1.00      0.11         6\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.50      0.01         2\n",
      "          88       0.19      0.80      0.31       248\n",
      "          89       0.03      0.67      0.06         3\n",
      "          90       0.08      0.68      0.15        25\n",
      "          91       0.18      0.56      0.27       200\n",
      "          92       0.03      0.67      0.06         9\n",
      "          93       0.08      0.40      0.14        50\n",
      "          94       0.05      0.38      0.09        13\n",
      "          95       0.05      0.26      0.09        34\n",
      "          96       0.03      0.47      0.05        17\n",
      "          97       0.16      0.62      0.26        48\n",
      "          98       0.00      1.00      0.01         1\n",
      "          99       0.20      0.95      0.33        81\n",
      "         100       0.49      1.00      0.65       100\n",
      "         101       0.05      0.61      0.09        18\n",
      "         102       0.01      1.00      0.02         3\n",
      "         103       0.06      1.00      0.12         5\n",
      "         104       0.11      0.70      0.20        10\n",
      "         105       0.33      1.00      0.50         6\n",
      "         106       0.04      1.00      0.07         3\n",
      "         107       0.05      0.50      0.09        14\n",
      "         108       0.12      0.77      0.21        22\n",
      "         109       0.04      0.17      0.07        54\n",
      "         110       0.03      0.46      0.05        13\n",
      "         111       0.05      0.25      0.08        12\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.07      0.97      0.14        33\n",
      "         114       0.40      0.75      0.52       270\n",
      "         115       0.11      0.35      0.17        51\n",
      "         116       0.25      0.97      0.39        34\n",
      "         117       0.17      1.00      0.29         4\n",
      "         118       0.15      0.57      0.23        91\n",
      "         119       0.04      0.80      0.08         5\n",
      "         120       0.19      0.73      0.30        11\n",
      "         121       0.09      0.50      0.15        28\n",
      "         122       0.20      0.89      0.33         9\n",
      "         123       0.37      0.71      0.48       166\n",
      "         124       0.03      0.33      0.05        18\n",
      "         125       0.12      0.86      0.21         7\n",
      "         126       0.06      0.31      0.10        13\n",
      "         127       0.19      0.66      0.30       239\n",
      "         128       0.30      0.80      0.44       276\n",
      "         129       0.02      0.67      0.04         6\n",
      "         130       0.19      0.77      0.31        35\n",
      "         131       0.33      0.92      0.49        13\n",
      "         132       0.01      1.00      0.01         2\n",
      "         133       0.02      1.00      0.03         5\n",
      "         134       0.01      0.50      0.03         2\n",
      "         135       0.02      1.00      0.04         2\n",
      "         136       0.08      0.47      0.14        75\n",
      "         137       0.00      0.00      0.00         7\n",
      "         138       0.07      0.49      0.12        67\n",
      "         139       0.37      0.48      0.42       318\n",
      "         140       0.02      0.30      0.04        10\n",
      "         141       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.17      0.71      0.27      9022\n",
      "   macro avg       0.16      0.65      0.22      9022\n",
      "weighted avg       0.31      0.71      0.41      9022\n",
      " samples avg       0.23      0.78      0.33      9022\n",
      "\n",
      "Time taken to run this cell : 0:32:28.468587\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', class_weight=\"balanced\"), n_jobs = -1)\n",
    "classifier.fit(x_train_6, y_train)\n",
    "predictions = classifier.predict(x_test_6)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Let us try topic modelling_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
